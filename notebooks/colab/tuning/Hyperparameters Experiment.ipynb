{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moral-rebound"
   },
   "source": [
    "# Boilerplate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crude-waste"
   },
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pillow\n",
    "from PIL import Image\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "# Misc\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4gBSNDrcfGl"
   },
   "source": [
    "# 1. Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcHbRtuHcd-N",
    "outputId": "70dc59a9-e75b-4543-a2fd-1ba711554312"
   },
   "outputs": [],
   "source": [
    "!git clone -b data https://github.com/Oxiang/50.039-Deep-Learning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3ElMDwpU831",
    "outputId": "87f3eaa8-5be1-4af9-f5b6-26a6a4181907"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4-h2B3OVCRe",
    "outputId": "0e54a787-30a7-45d0-8a7e-e8d8317642f7"
   },
   "outputs": [],
   "source": [
    "cd 50.039-Deep-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DW2ZD2afqdmF",
    "outputId": "bc49a72c-29e8-4a7a-859d-48f73b30dec0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "(\n",
    "tree dataset -d\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZhr10rHVlIj"
   },
   "outputs": [],
   "source": [
    "classes_n_c = {0: 'normal', 1: 'infected'}\n",
    "classes_inc_ic = {0: 'infected_non_covid', 1: 'infected_covid'}\n",
    "groups = ['train', 'test', 'val']\n",
    "dataset_numbers = {\n",
    "    'train_normal': 1341,\n",
    "    'train_infected_non_covid': 2530,\n",
    "    'train_infected_covid': 1345,\n",
    "    'val_normal': 8,\n",
    "    'val_infected_non_covid': 8,\n",
    "    'val_infected_covid': 8,    \n",
    "    'test_normal': 234,\n",
    "    'test_infected_non_covid': 242,\n",
    "    'test_infected_covid': 138,\n",
    "}\n",
    "dataset_paths = {\n",
    "    'train_normal': './dataset/train/normal/',\n",
    "    'train_infected_non_covid': './dataset/train/infected/non-covid/',\n",
    "    'train_infected_covid': './dataset/train/infected/covid/',\n",
    "    'val_normal': './dataset/val/normal/',\n",
    "    'val_infected_non_covid': './dataset/val/infected/non-covid/',\n",
    "    'val_infected_covid': './dataset/val/infected/covid/',    \n",
    "    'test_normal': './dataset/test/normal/',\n",
    "    'test_infected_non_covid': './dataset/test/infected/non-covid/',\n",
    "    'test_infected_covid': './dataset/test/infected/covid/',    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kakruEOWFn2"
   },
   "source": [
    "View one of the images and its properties. These images consist of a Numpy array, with values ranging between 0 and 255. These values will be normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jcs9foiNXKY1"
   },
   "source": [
    "# 2. Creating a Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pyf61XksuJjY"
   },
   "source": [
    "## 2.1 Common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Z0B8tOLuI-D"
   },
   "outputs": [],
   "source": [
    "binary_dataset_paths = {\n",
    "    'layer_0': {\n",
    "        'train': {\n",
    "            'train_normal':'./dataset/train/normal',\n",
    "            'train_infected': './dataset/train/infected'\n",
    "        },\n",
    "        'val': {\n",
    "            'val_normal':'./dataset/val/normal',\n",
    "            'val_infected': './dataset/val/infected'\n",
    "        },\n",
    "        'test': {\n",
    "            'test_normal':'./dataset/test/normal',\n",
    "            'test_infected': './dataset/test/infected'\n",
    "        }\n",
    "    },\n",
    "    'layer_1':{\n",
    "        'train': {\n",
    "            'train_covid': './dataset/train/infected/covid',\n",
    "            'train_non_covid' : './dataset/train/infected/non-covid'\n",
    "        },\n",
    "        'val': {\n",
    "            'val_covid': './dataset/val/infected/covid',\n",
    "            'val_non_covid' : './dataset/val/infected/non-covid'\n",
    "        },\n",
    "        'test': {\n",
    "            'test_covid': './dataset/test/infected/covid',\n",
    "            'test_non_covid' : './dataset/test/infected/non-covid'            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "binary_dataset_numbers = {\n",
    "    'layer_0': {\n",
    "        'train': {\n",
    "            'train_normal': 1341,\n",
    "            'train_infected': 3875\n",
    "        },\n",
    "        'val': {\n",
    "            'val_normal': 8,\n",
    "            'val_infected': 16\n",
    "        },\n",
    "        'test': {\n",
    "            'test_normal': 234,\n",
    "            'test_infected': 380\n",
    "        }\n",
    "    },\n",
    "    'layer_1':{\n",
    "        'train': {\n",
    "            'train_covid': 1345,\n",
    "            'train_non_covid' : 2530\n",
    "        },\n",
    "        'val': {\n",
    "            'val_covid': 8,\n",
    "            'val_non_covid': 8\n",
    "        },\n",
    "        'test': {\n",
    "            'test_covid': 138,\n",
    "            'test_non_covid': 242            \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKLCcIvxXLHu"
   },
   "source": [
    "## 2.2 Layer 0 General Dataset object that is custom made for train, val, test to individually use\n",
    "\n",
    "length method ( __ len __ )\n",
    "\n",
    "> return the number of images present in the dataset\n",
    "\n",
    "getitem method ( __ getitem __ )\n",
    "\n",
    "> fetch an image and its label, using a single index value. Returns the image, along with a one-hot vector corresponding to the class of the object. Both returned parameters will be torch tensors.\n",
    "- [1, 0] for normal class\n",
    "- [0, 1] for infected class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtNXQwKbXNfY"
   },
   "outputs": [],
   "source": [
    "class L0_Lung_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generic Dataset class for Layer 0\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, groups, dataset_numbers, dataset_paths, infected_sub_class_numbers):\n",
    "        \"\"\"\n",
    "        Constructor for generic Dataset class for Layer0 - assembles\n",
    "        the important parameters in attributes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        groups : str\n",
    "            Allowed values: train, val, test\n",
    "        dataset_numbers : dict\n",
    "            Count of each class within specified group (e.g. normal, infected)\n",
    "        dataset_paths : dict\n",
    "            Path to each class within specified group (infected has 2 sub-class dir)\n",
    "        \"\"\"\n",
    "\n",
    "        self.img_size = (150, 150)\n",
    "        self.classes = { 0: 'normal', 1: 'infected' }\n",
    "        self.covid_status = {0: '', 1: 'covid', 2: 'non-covid'} \n",
    "        self.groups = groups\n",
    "        self.dataset_numbers = dataset_numbers\n",
    "        self.dataset_paths = dataset_paths\n",
    "        self.infected_sub_class_numbers = infected_sub_class_numbers\n",
    "\n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Descriptor function.\n",
    "        Will print details about the dataset when called.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate description\n",
    "        msg = \"This is the {} dataset of the Lung Dataset\".format(self.groups)\n",
    "        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n",
    "        msg += \" in March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for key, val in self.dataset_paths.items():\n",
    "            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n",
    "        print(msg)\n",
    "        \n",
    "    \n",
    "    def open_img(self, group_val, class_val, covid_status, index_val):\n",
    "        \"\"\"\n",
    "        Opens image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal' or 'infected_non_covid' or 'infected_covid'.\n",
    "        - covid_status should take values in '', 'covid' or 'non_covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \n",
    "        Returns loaded image as a normalized Numpy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Asserts checking for consistency in passed parameters\n",
    "        err_msg = \"Error - group_val variable should be set to 'train', 'test' or 'val'.\"\n",
    "        assert group_val in self.groups, err_msg\n",
    "        \n",
    "        err_msg = \"Error - class_val variable should be set to 'normal' or 'infected_non_covid' or 'infected_covid.\"\n",
    "        assert class_val in self.classes.values(), err_msg\n",
    "\n",
    "        err_msg = \"Error - covid_status variable should be set to '', 'covid' or 'non-covid'.\"\n",
    "        assert covid_status in self.covid_status.values(), err_msg\n",
    "        \n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n",
    "        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n",
    "        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n",
    "        assert isinstance(index_val, int), err_msg\n",
    "        assert index_val >= 0 and index_val <= max_val, err_msg\n",
    "        \n",
    "        # 'normal' - example path: /dataset/train/normal/1.jpg\n",
    "        if covid_status == \"\":\n",
    "            path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n",
    "        # 'covid' or 'non_covid' - example path: './dataset/train/infected/covid/1.jpg',\n",
    "        else:\n",
    "            path_to_file = '{}/{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], covid_status, index_val)\n",
    "\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            # Convert to Numpy array and normalize pixel values by dividing by 255.\n",
    "            im = np.asarray(Image.open(f))/255\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    \n",
    "    def show_img(self, group_val, class_val, covid_status, index_val):\n",
    "        \"\"\"\n",
    "        Opens, then displays image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal' or 'infected'.\n",
    "        - covid_status should take values in '', 'covid' or 'non-covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open image\n",
    "        im = self.open_img(group_val, class_val, covid_status, index_val)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length special method, returns the number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Length function\n",
    "        return sum(self.dataset_numbers.values())\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getitem special method.\n",
    "        \n",
    "        Expects an integer value index, between 0 and len(self) - 1.\n",
    "        \n",
    "        Returns the image and its label as a one hot vector, both\n",
    "        in torch tensor format in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get item special method\n",
    "        first_val = int(list(self.dataset_numbers.values())[0])\n",
    "        if index < first_val:\n",
    "            class_val = 'normal'\n",
    "            label = torch.Tensor([1, 0])\n",
    "            covid_status = \"\"\n",
    "        else:\n",
    "            class_val = 'infected'\n",
    "            index = index - first_val\n",
    "            label = torch.Tensor([0, 1])\n",
    "            infected_covid_numbers = int(list(self.infected_sub_class_numbers.values())[0]) # covid\n",
    "            if index < infected_covid_numbers:\n",
    "                class_val = 'infected'\n",
    "                covid_status = 'covid'\n",
    "            else:\n",
    "                class_val = 'infected'\n",
    "                index = index - infected_covid_numbers\n",
    "                covid_status = 'non-covid'\n",
    "        im = self.open_img(self.groups, class_val, covid_status, index)\n",
    "        im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V714D12V5qgY"
   },
   "outputs": [],
   "source": [
    "def verify_l0_dataset(group,dataset,image_overall_index,class_val,covid_status,\n",
    "                   image_specific_dataset_index=1):\n",
    "  \"\"\"\n",
    "  Helper function to verify that the classes are implemented correctly\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  group : str\n",
    "      Allowed values: train, val, test\n",
    "  dataset: object\n",
    "      Object instantiated from the class\n",
    "  image_overall_index: int\n",
    "      Overall index in the full dataset across all classes\n",
    "  class_val: str\n",
    "      Image label. Example: normal, infected\n",
    "  covid_status: str\n",
    "      If class_val is 'infected', set this to either 'covid' or 'non-covid'\n",
    "  image_specific_dataset_index : int\n",
    "      image id in the specific nested directory\n",
    "  \"\"\"\n",
    "  print('Verify the special methods __len__ and __get_item__')\n",
    "  print('Number of images in {} dataset: {}'.format(group, len(dataset)))\n",
    "  print('Details for image id {} from the {} dataset'.format(\n",
    "      image_overall_index,\n",
    "      group\n",
    "  ))\n",
    "  im, class_oh = dataset[image_overall_index]\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  print('Sample image class: {}'.format(class_oh))\n",
    "\n",
    "  print('\\nVerify the open_img and show_img functions')\n",
    "  print('Open and show image {} from the {}_{} dataset'.format(\n",
    "      image_specific_dataset_index,\n",
    "      group,\n",
    "      class_val\n",
    "  ))\n",
    "  im = dataset.open_img(group, class_val, covid_status, image_specific_dataset_index)\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  dataset.show_img(group, class_val, covid_status, image_specific_dataset_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9CO29iBYHs-"
   },
   "source": [
    "### 2.2.1 Layer 0 Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBI4uwQqYiWI",
    "outputId": "85bd6cde-7de8-4d13-f673-c804d7b07afc"
   },
   "outputs": [],
   "source": [
    "train_group = 'train'\n",
    "l0_ld_train = L0_Lung_Dataset(groups = train_group,\n",
    "                              dataset_numbers = binary_dataset_numbers['layer_0'][train_group],\n",
    "                              dataset_paths = binary_dataset_paths['layer_0'][train_group],\n",
    "                              infected_sub_class_numbers = binary_dataset_numbers['layer_1'][train_group])\n",
    "l0_ld_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMz0d7zfY5W7"
   },
   "source": [
    "### 2.2.2 Layer 0 Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4Sju4KFY5p8",
    "outputId": "98d6791a-1db3-407d-f64b-b2e41913b942"
   },
   "outputs": [],
   "source": [
    "val_group = 'val'\n",
    "l0_ld_val = L0_Lung_Dataset(groups = val_group,\n",
    "                            dataset_numbers = binary_dataset_numbers['layer_0'][val_group],\n",
    "                            dataset_paths = binary_dataset_paths['layer_0'][val_group],\n",
    "                            infected_sub_class_numbers = binary_dataset_numbers['layer_1'][val_group])\n",
    "l0_ld_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojan7nynZILA"
   },
   "source": [
    "### 2.2.3 Layer 0 Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdxD1NzmZIvq",
    "outputId": "8c7d32f1-846f-409a-8e31-b360cb41dd95"
   },
   "outputs": [],
   "source": [
    "test_group = 'test'\n",
    "l0_ld_test = L0_Lung_Dataset(groups = test_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_0'][test_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_0'][test_group],\n",
    "                              infected_sub_class_numbers = binary_dataset_numbers['layer_1'][test_group])\n",
    "l0_ld_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRmEfd3Z2ccn"
   },
   "source": [
    "## 2.3 Layer 1 General Dataset object that is custom made for train, val, test to individually use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWR5VOpK2pan"
   },
   "outputs": [],
   "source": [
    "class L1_Lung_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generic Dataset class for Layer 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, groups, dataset_numbers, dataset_paths):\n",
    "        \"\"\"\n",
    "        Constructor for generic Dataset class for Layer0 - assembles\n",
    "        the important parameters in attributes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        groups : str\n",
    "            Allowed values: train, val, test\n",
    "        dataset_numbers : dict\n",
    "            Count of each class within specified group (e.g. covid, non_covid)\n",
    "        dataset_paths : dict\n",
    "            Path to each class within specified group (infected has 2 sub-class dir)\n",
    "        \"\"\"\n",
    "\n",
    "        self.img_size = (150, 150)\n",
    "        self.classes = {0: 'covid', 1: 'non_covid'}\n",
    "        self.groups = groups\n",
    "        self.dataset_numbers = dataset_numbers\n",
    "        self.dataset_paths = dataset_paths\n",
    "\n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Descriptor function.\n",
    "        Will print details about the dataset when called.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate description\n",
    "        msg = \"This is the {} dataset of the Lung Dataset\".format(self.groups)\n",
    "        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n",
    "        msg += \" in March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for key, val in self.dataset_paths.items():\n",
    "            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n",
    "        print(msg)\n",
    "        \n",
    "    \n",
    "    def open_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'covid' or 'non-covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \n",
    "        Returns loaded image as a normalized Numpy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Asserts checking for consistency in passed parameters\n",
    "        err_msg = \"Error - group_val variable should be set to 'train', 'test' or 'val'.\"\n",
    "        assert group_val in self.groups, err_msg\n",
    "        \n",
    "        err_msg = \"Error - class_val variable should be set to 'covid' or 'non-covid'.\"\n",
    "        assert class_val in self.classes.values(), err_msg     \n",
    "        \n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n",
    "        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n",
    "        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n",
    "        assert isinstance(index_val, int), err_msg\n",
    "        assert index_val >= 0 and index_val <= max_val, err_msg\n",
    "        \n",
    "        # Open file as before\n",
    "        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            im = np.asarray(Image.open(f))/255\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    \n",
    "    def show_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens, then displays image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'covid' or 'non-covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open image\n",
    "        im = self.open_img(group_val, class_val, index_val)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length special method, returns the number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Length function\n",
    "        return sum(self.dataset_numbers.values())\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getitem special method.\n",
    "        \n",
    "        Expects an integer value index, between 0 and len(self) - 1.\n",
    "        \n",
    "        Returns the image and its label as a one hot vector, both\n",
    "        in torch tensor format in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get item special method\n",
    "        first_val = int(list(self.dataset_numbers.values())[0])\n",
    "        if index < first_val:\n",
    "            class_val = 'covid'\n",
    "            label = torch.Tensor([1, 0])\n",
    "        else:\n",
    "            class_val = 'non_covid'\n",
    "            index = index - first_val\n",
    "            label = torch.Tensor([0, 1])\n",
    "\n",
    "        im = self.open_img(self.groups, class_val, index)\n",
    "        im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MB6wqXUN5wMd"
   },
   "outputs": [],
   "source": [
    "def verify_l1_dataset(group,dataset,image_overall_index,class_val,\n",
    "                   image_specific_dataset_index=1):\n",
    "  \"\"\"\n",
    "  Helper function to verify that the classes are implemented correctly\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  group : str\n",
    "      Allowed values: train, val, test\n",
    "  dataset: object\n",
    "      Object instantiated from the class\n",
    "  image_overall_index: int\n",
    "      Overall index in the full dataset across all classes\n",
    "  class_val: str\n",
    "      Image label. Example: covid, non-covid\n",
    "  image_specific_dataset_index : int\n",
    "      image id in the specific nested directory\n",
    "  \"\"\"\n",
    "  print('Verify the special methods __len__ and __get_item__')\n",
    "  print('Number of images in {} dataset: {}'.format(group, len(dataset)))\n",
    "  print('Details for image id {} from the {} dataset'.format(\n",
    "      image_overall_index,\n",
    "      group\n",
    "  ))\n",
    "  im, class_oh = dataset[image_overall_index]\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  print('Sample image class: {}'.format(class_oh))\n",
    "\n",
    "  print('\\nVerify the open_img and show_img functions')\n",
    "  print('Open and show image {} from the {}_{} dataset'.format(\n",
    "      image_specific_dataset_index,\n",
    "      group,\n",
    "      class_val\n",
    "  ))\n",
    "  im = dataset.open_img(group, class_val, image_specific_dataset_index)\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  dataset.show_img(group, class_val, image_specific_dataset_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIeOkWaC2n3U"
   },
   "source": [
    "### 2.3.1 Layer 1 Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McMnU4Jm6X58",
    "outputId": "9379e5db-1023-4da9-e66b-2de0054528b3"
   },
   "outputs": [],
   "source": [
    "train_group = 'train'\n",
    "l1_ld_train = L1_Lung_Dataset(groups = train_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_1'][train_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_1'][train_group])\n",
    "l1_ld_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZt-Y09H2gcy"
   },
   "source": [
    "### 2.3.2 Layer 1 Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UP8YEmM48GAs",
    "outputId": "b86ad0d3-5039-41d3-f3b1-788cba8935cb"
   },
   "outputs": [],
   "source": [
    "val_group = 'val'\n",
    "l1_ld_val = L1_Lung_Dataset(groups = val_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_1'][val_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_1'][val_group])\n",
    "l1_ld_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSZCUuuS6RLL"
   },
   "source": [
    "### 2.3.3 Layer 1 Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx5IOpZN8Gws",
    "outputId": "a1d3361c-11f1-45ab-bafa-62a48b9173f5"
   },
   "outputs": [],
   "source": [
    "test_group = 'test'\n",
    "l1_ld_test = L1_Lung_Dataset(groups = test_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_1'][test_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_1'][test_group])\n",
    "l1_ld_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC14yqAz2vSI"
   },
   "source": [
    "# 3. Creating a data loader object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5YY_qNrFUTw"
   },
   "source": [
    "## 3.1 Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiftrqf62usb"
   },
   "outputs": [],
   "source": [
    "l0_bs_train = 32\n",
    "l0_bs_test = 32\n",
    "l0_bs_val = 1\n",
    "l0_train_loader = DataLoader(l0_ld_train, batch_size = l0_bs_train, shuffle = True)\n",
    "l0_test_loader = DataLoader(l0_ld_test, batch_size = l0_bs_test, shuffle = True)\n",
    "l0_val_loader = DataLoader(l0_ld_val, batch_size = l0_bs_val, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4Fv6HyVFsfa"
   },
   "source": [
    "## 3.2 Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpHtBlbSFTZW"
   },
   "outputs": [],
   "source": [
    "l1_bs_train = 32\n",
    "l1_bs_test = 32\n",
    "l1_bs_val = 1\n",
    "l1_train_loader = DataLoader(l1_ld_train, batch_size = l1_bs_train, shuffle = True)\n",
    "l1_test_loader = DataLoader(l1_ld_test, batch_size = l1_bs_test, shuffle = True)\n",
    "l1_val_loader = DataLoader(l1_ld_val, batch_size = l1_bs_val, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x_-1Qe34U5w"
   },
   "source": [
    "# 4. Model\n",
    "\n",
    "https://link.springer.com/article/10.1007/s12652-021-02917-3#Sec9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVfcawPjF5sl"
   },
   "source": [
    "## 4.1 Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yJ7JTk04XIu"
   },
   "outputs": [],
   "source": [
    "class L0_Net(nn.Module):\n",
    "    def __init__(self, num_layers=1):\n",
    "        super(L0_Net, self).__init__()\n",
    "        # Conv2D: 1 input channel, 4 output channels, 3 by 3 kernel, stride of 1.\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(8, 32, 3, 1)\n",
    "        self.avgpool = nn.AvgPool2d(3)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "        self.fc1 = nn.Linear(16928, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJKx7kXTQYQN",
    "outputId": "3b65b8c6-a923-4f89-f83e-8962961cd577"
   },
   "outputs": [],
   "source": [
    "# Activate gpu\n",
    "if torch.cuda.is_available():  \n",
    "    print('using GPU')\n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "l0_model = L0_Net().to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoBbl4-OO417",
    "outputId": "f3d2aa22-250a-4198-deea-5bed17428e29"
   },
   "outputs": [],
   "source": [
    "summary(l0_model, (1, 150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUtueamzGHp9"
   },
   "source": [
    "## 4.2 Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "El3FLR03GJ5m"
   },
   "outputs": [],
   "source": [
    "class L1_Net(nn.Module):\n",
    "    def __init__(self, num_layers=1):\n",
    "        super(L1_Net, self).__init__()\n",
    "        # Conv2D: 1 input channel, 4 output channels, 3 by 3 kernel, stride of 1.\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(8, 32, 3, 1)\n",
    "        self.avgpool = nn.AvgPool2d(3)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "        self.fc1 = nn.Linear(16928, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3uSnZgeGKO-",
    "outputId": "af1fa8f1-4e48-4b26-a9a3-30c0892902d9"
   },
   "outputs": [],
   "source": [
    "# Activate gpu\n",
    "if torch.cuda.is_available():  \n",
    "    print('using GPU')\n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "l1_model = L1_Net().to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tRV7PJIGPTH",
    "outputId": "02c17861-2d3b-4165-bcac-46bb06c4cb4b"
   },
   "outputs": [],
   "source": [
    "summary(l1_model, (1, 150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1E4MDvTLdnP"
   },
   "source": [
    "# 5. Training the model\n",
    "\n",
    "Reference material: [Towards data science: PyTorch [Tabular] â€” Multiclass Classification](https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98hO2OLpLdRK"
   },
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.1 GridSearch for Layer 0\n",
    "\n",
    "## Hyperparameters \n",
    "epochs = [5, 10]\n",
    "lr = [0.0001, 0.00001]\n",
    "scheduler_gamma = [0.1, 0.001]\n",
    "weight_decay = [0, 0.0005]\n",
    "Optimizer = Adam, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_L0(epochs, lr, scheduler_gamma, weight_decay, use_adam= True,log_path='../tuning_layer_0_hyperparameters.log'):\n",
    "    \n",
    "    # Activate gpu\n",
    "    if torch.cuda.is_available():  \n",
    "        print('using GPU')\n",
    "        device = \"cuda:0\" \n",
    "    else:  \n",
    "        device = \"cpu\"\n",
    "        \n",
    "    # Load a fresh network\n",
    "    l0_model = L0_Net().to(torch.device(device))\n",
    "    \n",
    "    # setup\n",
    "    l0_class_weights = torch.tensor([2.83, 1.0]).to(torch.device(device))\n",
    "    criterion = nn.CrossEntropyLoss(l0_class_weights)\n",
    "    if use_adam:\n",
    "        optimizer = optim.Adam(l0_model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.AdamW(l0_model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=scheduler_gamma)\n",
    "    \n",
    "    start = time.time()\n",
    "    start_model_time = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    \n",
    "    # Save log for hyperparameters\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(\"{} : Training L0 model - epochs {} - lr {} - scheduler_gamma {} - weight_decay - {} - use_adam {} \\n\".format(start_model_time, epochs, lr, scheduler_gamma, weight_decay, use_adam))\n",
    "    \n",
    "    l0_accuracy_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "    l0_loss_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_acc = 0\n",
    "\n",
    "        l0_model.train()\n",
    "        for batch_idx, (X_train_batch, y_train_batch) in enumerate(l0_train_loader):\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = l0_model.forward(X_train_batch)\n",
    "            train_loss  = criterion(output, torch.max(y_train_batch, 1)[1])\n",
    "            train_acc = multi_acc(output, torch.max(y_train_batch, 1)[1])\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step(e + batch_idx / len(l0_train_loader))\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            train_epoch_acc += train_acc.item()\n",
    "            \n",
    "        # update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # testing\n",
    "        with torch.no_grad():\n",
    "            test_epoch_loss = 0\n",
    "            test_epoch_acc = 0\n",
    "            l0_model.eval()\n",
    "            for X_test_batch, y_test_batch in l0_test_loader:\n",
    "                X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "\n",
    "                y_test_pred = l0_model.forward(X_test_batch)\n",
    "\n",
    "                test_loss = criterion(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "                test_acc = multi_acc(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "\n",
    "                test_epoch_loss += test_loss.item()\n",
    "                test_epoch_acc += test_acc.item()\n",
    "\n",
    "\n",
    "        # averaged\n",
    "        train_epoch_loss = train_epoch_loss/len(l0_train_loader)\n",
    "        train_epoch_acc = train_epoch_acc/len(l0_train_loader)\n",
    "        test_epoch_loss = test_epoch_loss/len(l0_test_loader)\n",
    "        test_epoch_acc = test_epoch_acc/len(l0_test_loader)\n",
    "\n",
    "        # The step number corresponds to the number of batches seen\n",
    "        now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        print(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now),\n",
    "          \"Training Loss: {:.4f} - \".format(train_epoch_loss),\n",
    "          \"Training Accuracy: {:.4f} -\".format(train_epoch_acc),\n",
    "          \"Test Loss: {:.4f} - \".format(test_epoch_loss),\n",
    "          \"Test Accuracy: {:.4f}\".format(test_epoch_acc))\n",
    "        l0_model.train()\n",
    "        \n",
    "        # save the logs\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now))\n",
    "            f.write(\"Training Loss: {:.4f} - \".format(train_epoch_loss))\n",
    "            f.write(\"Training Accuracy: {:.4f} - \".format(train_epoch_acc))\n",
    "            f.write(\"Test Loss: {:.4f} - \".format(test_epoch_loss))\n",
    "            f.write(\"Test Accuracy: {:.4f}\\n\\n\".format(test_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs\n",
    "train_model_L0(epochs= 5, lr=0.0001, scheduler_gamma=0.1, weight_decay=0)\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.1, weight_decay=0)\n",
    "\n",
    "# learning rate\n",
    "train_model_L0(epochs= 10, lr=0.00001, scheduler_gamma=0.1, weight_decay=0)\n",
    "train_model_L0(epochs= 10, lr=0.001, scheduler_gamma=0.1, weight_decay=0)\n",
    "\n",
    "# # scheduler gamma\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.001, weight_decay=0)\n",
    "\n",
    "# # weight decay\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.1, weight_decay=0.0005)\n",
    "\n",
    "# # AdamW\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.1, weight_decay=0, use_adam= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRYDiwdsL4vB"
   },
   "source": [
    "## 5.2 Layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.1 GridSearch for Layer 1\n",
    "hyperparameters\n",
    "'epochs': [5, 10] 'lr': [0.0001, 0.00001] 'scheduler_gamma': [0.1, 0.001] 'l1_lambda': [0.5, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_L1(epochs, lr, scheduler_gamma, weight_decay, use_adam= True,log_path='../tuning_layer_1_hyperparameters.log'):\n",
    "    \n",
    "    # Activate gpu\n",
    "    if torch.cuda.is_available():  \n",
    "        print('using GPU')\n",
    "        device = \"cuda:0\" \n",
    "    else:  \n",
    "        device = \"cpu\"\n",
    "        \n",
    "    # Load a fresh network\n",
    "    l1_model = L1_Net().to(torch.device(device))\n",
    "    \n",
    "    # setup\n",
    "    weight_decay = 0.00001\n",
    "    l1_class_weights = torch.tensor([2.83, 1.0]).to(torch.device(device))\n",
    "    criterion = nn.CrossEntropyLoss(l1_class_weights)\n",
    "    optimizer = optim.AdamW(l1_model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=scheduler_gamma)\n",
    "    \n",
    "    start = time.time()\n",
    "    start_model_time = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    \n",
    "    L1_reg = torch.tensor(0., requires_grad=True)\n",
    "    for name, param in l1_model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            L1_reg = L1_reg + torch.norm(param, 1)\n",
    "    \n",
    "    # Save log for hyperparameters\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(\"{} : Training L0 model - epochs {} - lr {} - scheduler_gamma {} - weight_decay - {} - use_adam {} \\n\".format(start_model_time, epochs, lr, scheduler_gamma, weight_decay, use_adam))\n",
    "    \n",
    "    l1_accuracy_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "    l1_loss_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_acc = 0\n",
    "\n",
    "        l1_model.train()\n",
    "        for batch_idx, (X_train_batch, y_train_batch) in enumerate(l1_train_loader):\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = l1_model.forward(X_train_batch)\n",
    "            train_loss  = criterion(output, torch.max(y_train_batch, 1)[1])\n",
    "            train_acc = multi_acc(output, torch.max(y_train_batch, 1)[1])\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            train_epoch_acc += train_acc.item()\n",
    "            \n",
    "        # update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # testing\n",
    "        with torch.no_grad():\n",
    "            test_epoch_loss = 0\n",
    "            test_epoch_acc = 0\n",
    "            l1_model.eval()\n",
    "            for X_test_batch, y_test_batch in l1_test_loader:\n",
    "                X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "\n",
    "                y_test_pred = l1_model.forward(X_test_batch)\n",
    "\n",
    "                test_loss = criterion(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "                test_acc = multi_acc(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "\n",
    "                test_epoch_loss += test_loss.item()\n",
    "                test_epoch_acc += test_acc.item()\n",
    "\n",
    "\n",
    "        # averaged\n",
    "        train_epoch_loss = train_epoch_loss/len(l1_train_loader)\n",
    "        train_epoch_acc = train_epoch_acc/len(l1_train_loader)\n",
    "        test_epoch_loss = test_epoch_loss/len(l1_test_loader)\n",
    "        test_epoch_acc = test_epoch_acc/len(l1_test_loader)\n",
    "\n",
    "        # The step number corresponds to the number of batches seen\n",
    "        now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        print(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now),\n",
    "          \"Training Loss: {:.4f} - \".format(train_epoch_loss),\n",
    "          \"Training Accuracy: {:.4f}\".format(train_epoch_acc),\n",
    "          \"Test Loss: {:.4f} - \".format(test_epoch_loss),\n",
    "          \"Test Accuracy: {:.4f}\".format(test_epoch_acc))\n",
    "        l1_model.train()\n",
    "\n",
    "        # Epoch metrics\n",
    "        l1_loss_stats_epoch['train'].append(train_epoch_loss)\n",
    "        l1_loss_stats_epoch['test'].append(test_epoch_loss)\n",
    "        l1_loss_stats_epoch['epoch'].append(e+1)\n",
    "        l1_accuracy_stats_epoch['train'].append(train_epoch_acc)\n",
    "        l1_accuracy_stats_epoch['test'].append(test_epoch_acc)\n",
    "        l1_accuracy_stats_epoch['epoch'].append(e+1)\n",
    "\n",
    "        # save the logs\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now))\n",
    "            f.write(\"Training Loss: {:.4f} - \".format(train_epoch_loss))\n",
    "            f.write(\"Training Accuracy: {:.4f} - \".format(train_epoch_acc))\n",
    "            f.write(\"Test Loss: {:.4f} - \".format(test_epoch_loss))\n",
    "            f.write(\"Test Accuracy: {:.4f}\\\\n\".format(test_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs\n",
    "train_model_L1(epochs= 5, lr=0.0001, scheduler_gamma=0.1, weight_decay=0)\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.1, weight_decay=0)\n",
    "\n",
    "# learning rate\n",
    "train_model_L1(epochs= 10, lr=0.00001, scheduler_gamma=0.1, weight_decay=0)\n",
    "train_model_L1(epochs= 10, lr=0.001, scheduler_gamma=0.1, weight_decay=0)\n",
    "\n",
    "# # scheduler gamma\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.001, weight_decay=0)\n",
    "\n",
    "# # weight decay\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.1, weight_decay=0.0005)\n",
    "\n",
    "# # AdamW\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.1, weight_decay=0, use_adam= False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "custom_dataset_dataloader_cascade.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
