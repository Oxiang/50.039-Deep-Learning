{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moral-rebound"
   },
   "source": [
    "# Boilerplate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "crude-waste"
   },
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pillow\n",
    "from PIL import Image\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "# Misc\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4gBSNDrcfGl"
   },
   "source": [
    "# 1. Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcHbRtuHcd-N",
    "outputId": "70dc59a9-e75b-4543-a2fd-1ba711554312"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '50.039-Deep-Learning'...\n",
      "Updating files:  26% (1565/5962)\n",
      "Updating files:  27% (1610/5962)\n",
      "Updating files:  28% (1670/5962)\n",
      "Updating files:  29% (1729/5962)\n",
      "Updating files:  30% (1789/5962)\n",
      "Updating files:  31% (1849/5962)\n",
      "Updating files:  32% (1908/5962)\n",
      "Updating files:  33% (1968/5962)\n",
      "Updating files:  34% (2028/5962)\n",
      "Updating files:  35% (2087/5962)\n",
      "Updating files:  36% (2147/5962)\n",
      "Updating files:  37% (2206/5962)\n",
      "Updating files:  38% (2266/5962)\n",
      "Updating files:  39% (2326/5962)\n",
      "Updating files:  40% (2385/5962)\n",
      "Updating files:  41% (2445/5962)\n",
      "Updating files:  42% (2505/5962)\n",
      "Updating files:  43% (2564/5962)\n",
      "Updating files:  44% (2624/5962)\n",
      "Updating files:  45% (2683/5962)\n",
      "Updating files:  46% (2743/5962)\n",
      "Updating files:  47% (2803/5962)\n",
      "Updating files:  48% (2862/5962)\n",
      "Updating files:  49% (2922/5962)\n",
      "Updating files:  50% (2981/5962)\n",
      "Updating files:  51% (3041/5962)\n",
      "Updating files:  52% (3101/5962)\n",
      "Updating files:  53% (3160/5962)\n",
      "Updating files:  54% (3220/5962)\n",
      "Updating files:  54% (3268/5962)\n",
      "Updating files:  55% (3280/5962)\n",
      "Updating files:  56% (3339/5962)\n",
      "Updating files:  57% (3399/5962)\n",
      "Updating files:  58% (3458/5962)\n",
      "Updating files:  59% (3518/5962)\n",
      "Updating files:  60% (3578/5962)\n",
      "Updating files:  61% (3637/5962)\n",
      "Updating files:  62% (3697/5962)\n",
      "Updating files:  63% (3757/5962)\n",
      "Updating files:  64% (3816/5962)\n",
      "Updating files:  65% (3876/5962)\n",
      "Updating files:  66% (3935/5962)\n",
      "Updating files:  67% (3995/5962)\n",
      "Updating files:  68% (4055/5962)\n",
      "Updating files:  69% (4114/5962)\n",
      "Updating files:  70% (4174/5962)\n",
      "Updating files:  71% (4234/5962)\n",
      "Updating files:  72% (4293/5962)\n",
      "Updating files:  73% (4353/5962)\n",
      "Updating files:  74% (4412/5962)\n",
      "Updating files:  75% (4472/5962)\n",
      "Updating files:  76% (4532/5962)\n",
      "Updating files:  77% (4591/5962)\n",
      "Updating files:  78% (4651/5962)\n",
      "Updating files:  78% (4689/5962)\n",
      "Updating files:  79% (4710/5962)\n",
      "Updating files:  80% (4770/5962)\n",
      "Updating files:  81% (4830/5962)\n",
      "Updating files:  82% (4889/5962)\n",
      "Updating files:  83% (4949/5962)\n",
      "Updating files:  84% (5009/5962)\n",
      "Updating files:  85% (5068/5962)\n",
      "Updating files:  86% (5128/5962)\n",
      "Updating files:  87% (5187/5962)\n",
      "Updating files:  88% (5247/5962)\n",
      "Updating files:  89% (5307/5962)\n",
      "Updating files:  90% (5366/5962)\n",
      "Updating files:  91% (5426/5962)\n",
      "Updating files:  92% (5486/5962)\n",
      "Updating files:  93% (5545/5962)\n",
      "Updating files:  94% (5605/5962)\n",
      "Updating files:  95% (5664/5962)\n",
      "Updating files:  96% (5724/5962)\n",
      "Updating files:  97% (5784/5962)\n",
      "Updating files:  98% (5843/5962)\n",
      "Updating files:  99% (5903/5962)\n",
      "Updating files: 100% (5962/5962)\n",
      "Updating files: 100% (5962/5962), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b data https://github.com/Oxiang/50.039-Deep-Learning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3ElMDwpU831",
    "outputId": "87f3eaa8-5be1-4af9-f5b6-26a6a4181907"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4-h2B3OVCRe",
    "outputId": "0e54a787-30a7-45d0-8a7e-e8d8317642f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sceps\\OneDrive\\Personal Folder\\SUTD Deep Learning\\small project final\\50.039-Deep-Learning\\notebooks\\colab\\gridsearch\\50.039-Deep-Learning\n"
     ]
    }
   ],
   "source": [
    "cd 50.039-Deep-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DW2ZD2afqdmF",
    "outputId": "bc49a72c-29e8-4a7a-859d-48f73b30dec0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "(\n",
    "tree dataset -d\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NZhr10rHVlIj"
   },
   "outputs": [],
   "source": [
    "classes_n_c = {0: 'normal', 1: 'infected'}\n",
    "classes_inc_ic = {0: 'infected_non_covid', 1: 'infected_covid'}\n",
    "groups = ['train', 'test', 'val']\n",
    "dataset_numbers = {\n",
    "    'train_normal': 1341,\n",
    "    'train_infected_non_covid': 2530,\n",
    "    'train_infected_covid': 1345,\n",
    "    'val_normal': 8,\n",
    "    'val_infected_non_covid': 8,\n",
    "    'val_infected_covid': 8,    \n",
    "    'test_normal': 234,\n",
    "    'test_infected_non_covid': 242,\n",
    "    'test_infected_covid': 138,\n",
    "}\n",
    "dataset_paths = {\n",
    "    'train_normal': './dataset/train/normal/',\n",
    "    'train_infected_non_covid': './dataset/train/infected/non-covid/',\n",
    "    'train_infected_covid': './dataset/train/infected/covid/',\n",
    "    'val_normal': './dataset/val/normal/',\n",
    "    'val_infected_non_covid': './dataset/val/infected/non-covid/',\n",
    "    'val_infected_covid': './dataset/val/infected/covid/',    \n",
    "    'test_normal': './dataset/test/normal/',\n",
    "    'test_infected_non_covid': './dataset/test/infected/non-covid/',\n",
    "    'test_infected_covid': './dataset/test/infected/covid/',    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kakruEOWFn2"
   },
   "source": [
    "View one of the images and its properties. These images consist of a Numpy array, with values ranging between 0 and 255. These values will be normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jcs9foiNXKY1"
   },
   "source": [
    "# 2. Creating a Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pyf61XksuJjY"
   },
   "source": [
    "## 2.1 Common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1Z0B8tOLuI-D"
   },
   "outputs": [],
   "source": [
    "binary_dataset_paths = {\n",
    "    'layer_0': {\n",
    "        'train': {\n",
    "            'train_normal':'./dataset/train/normal',\n",
    "            'train_infected': './dataset/train/infected'\n",
    "        },\n",
    "        'val': {\n",
    "            'val_normal':'./dataset/val/normal',\n",
    "            'val_infected': './dataset/val/infected'\n",
    "        },\n",
    "        'test': {\n",
    "            'test_normal':'./dataset/test/normal',\n",
    "            'test_infected': './dataset/test/infected'\n",
    "        }\n",
    "    },\n",
    "    'layer_1':{\n",
    "        'train': {\n",
    "            'train_covid': './dataset/train/infected/covid',\n",
    "            'train_non_covid' : './dataset/train/infected/non-covid'\n",
    "        },\n",
    "        'val': {\n",
    "            'val_covid': './dataset/val/infected/covid',\n",
    "            'val_non_covid' : './dataset/val/infected/non-covid'\n",
    "        },\n",
    "        'test': {\n",
    "            'test_covid': './dataset/test/infected/covid',\n",
    "            'test_non_covid' : './dataset/test/infected/non-covid'            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "binary_dataset_numbers = {\n",
    "    'layer_0': {\n",
    "        'train': {\n",
    "            'train_normal': 1341,\n",
    "            'train_infected': 3875\n",
    "        },\n",
    "        'val': {\n",
    "            'val_normal': 8,\n",
    "            'val_infected': 16\n",
    "        },\n",
    "        'test': {\n",
    "            'test_normal': 234,\n",
    "            'test_infected': 380\n",
    "        }\n",
    "    },\n",
    "    'layer_1':{\n",
    "        'train': {\n",
    "            'train_covid': 1345,\n",
    "            'train_non_covid' : 2530\n",
    "        },\n",
    "        'val': {\n",
    "            'val_covid': 8,\n",
    "            'val_non_covid': 8\n",
    "        },\n",
    "        'test': {\n",
    "            'test_covid': 138,\n",
    "            'test_non_covid': 242            \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKLCcIvxXLHu"
   },
   "source": [
    "## 2.2 Layer 0 General Dataset object that is custom made for train, val, test to individually use\n",
    "\n",
    "length method ( __ len __ )\n",
    "\n",
    "> return the number of images present in the dataset\n",
    "\n",
    "getitem method ( __ getitem __ )\n",
    "\n",
    "> fetch an image and its label, using a single index value. Returns the image, along with a one-hot vector corresponding to the class of the object. Both returned parameters will be torch tensors.\n",
    "- [1, 0] for normal class\n",
    "- [0, 1] for infected class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LtNXQwKbXNfY"
   },
   "outputs": [],
   "source": [
    "class L0_Lung_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generic Dataset class for Layer 0\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, groups, dataset_numbers, dataset_paths, infected_sub_class_numbers):\n",
    "        \"\"\"\n",
    "        Constructor for generic Dataset class for Layer0 - assembles\n",
    "        the important parameters in attributes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        groups : str\n",
    "            Allowed values: train, val, test\n",
    "        dataset_numbers : dict\n",
    "            Count of each class within specified group (e.g. normal, infected)\n",
    "        dataset_paths : dict\n",
    "            Path to each class within specified group (infected has 2 sub-class dir)\n",
    "        \"\"\"\n",
    "\n",
    "        self.img_size = (150, 150)\n",
    "        self.classes = { 0: 'normal', 1: 'infected' }\n",
    "        self.covid_status = {0: '', 1: 'covid', 2: 'non-covid'} \n",
    "        self.groups = groups\n",
    "        self.dataset_numbers = dataset_numbers\n",
    "        self.dataset_paths = dataset_paths\n",
    "        self.infected_sub_class_numbers = infected_sub_class_numbers\n",
    "\n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Descriptor function.\n",
    "        Will print details about the dataset when called.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate description\n",
    "        msg = \"This is the {} dataset of the Lung Dataset\".format(self.groups)\n",
    "        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n",
    "        msg += \" in March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for key, val in self.dataset_paths.items():\n",
    "            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n",
    "        print(msg)\n",
    "        \n",
    "    \n",
    "    def open_img(self, group_val, class_val, covid_status, index_val):\n",
    "        \"\"\"\n",
    "        Opens image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal' or 'infected_non_covid' or 'infected_covid'.\n",
    "        - covid_status should take values in '', 'covid' or 'non_covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \n",
    "        Returns loaded image as a normalized Numpy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Asserts checking for consistency in passed parameters\n",
    "        err_msg = \"Error - group_val variable should be set to 'train', 'test' or 'val'.\"\n",
    "        assert group_val in self.groups, err_msg\n",
    "        \n",
    "        err_msg = \"Error - class_val variable should be set to 'normal' or 'infected_non_covid' or 'infected_covid.\"\n",
    "        assert class_val in self.classes.values(), err_msg\n",
    "\n",
    "        err_msg = \"Error - covid_status variable should be set to '', 'covid' or 'non-covid'.\"\n",
    "        assert covid_status in self.covid_status.values(), err_msg\n",
    "        \n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n",
    "        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n",
    "        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n",
    "        assert isinstance(index_val, int), err_msg\n",
    "        assert index_val >= 0 and index_val <= max_val, err_msg\n",
    "        \n",
    "        # 'normal' - example path: /dataset/train/normal/1.jpg\n",
    "        if covid_status == \"\":\n",
    "            path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n",
    "        # 'covid' or 'non_covid' - example path: './dataset/train/infected/covid/1.jpg',\n",
    "        else:\n",
    "            path_to_file = '{}/{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], covid_status, index_val)\n",
    "\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            # Convert to Numpy array and normalize pixel values by dividing by 255.\n",
    "            im = np.asarray(Image.open(f))/255\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    \n",
    "    def show_img(self, group_val, class_val, covid_status, index_val):\n",
    "        \"\"\"\n",
    "        Opens, then displays image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal' or 'infected'.\n",
    "        - covid_status should take values in '', 'covid' or 'non-covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open image\n",
    "        im = self.open_img(group_val, class_val, covid_status, index_val)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length special method, returns the number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Length function\n",
    "        return sum(self.dataset_numbers.values())\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getitem special method.\n",
    "        \n",
    "        Expects an integer value index, between 0 and len(self) - 1.\n",
    "        \n",
    "        Returns the image and its label as a one hot vector, both\n",
    "        in torch tensor format in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get item special method\n",
    "        first_val = int(list(self.dataset_numbers.values())[0])\n",
    "        if index < first_val:\n",
    "            class_val = 'normal'\n",
    "            label = torch.Tensor([1, 0])\n",
    "            covid_status = \"\"\n",
    "        else:\n",
    "            class_val = 'infected'\n",
    "            index = index - first_val\n",
    "            label = torch.Tensor([0, 1])\n",
    "            infected_covid_numbers = int(list(self.infected_sub_class_numbers.values())[0]) # covid\n",
    "            if index < infected_covid_numbers:\n",
    "                class_val = 'infected'\n",
    "                covid_status = 'covid'\n",
    "            else:\n",
    "                class_val = 'infected'\n",
    "                index = index - infected_covid_numbers\n",
    "                covid_status = 'non-covid'\n",
    "        im = self.open_img(self.groups, class_val, covid_status, index)\n",
    "        im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "V714D12V5qgY"
   },
   "outputs": [],
   "source": [
    "def verify_l0_dataset(group,dataset,image_overall_index,class_val,covid_status,\n",
    "                   image_specific_dataset_index=1):\n",
    "  \"\"\"\n",
    "  Helper function to verify that the classes are implemented correctly\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  group : str\n",
    "      Allowed values: train, val, test\n",
    "  dataset: object\n",
    "      Object instantiated from the class\n",
    "  image_overall_index: int\n",
    "      Overall index in the full dataset across all classes\n",
    "  class_val: str\n",
    "      Image label. Example: normal, infected\n",
    "  covid_status: str\n",
    "      If class_val is 'infected', set this to either 'covid' or 'non-covid'\n",
    "  image_specific_dataset_index : int\n",
    "      image id in the specific nested directory\n",
    "  \"\"\"\n",
    "  print('Verify the special methods __len__ and __get_item__')\n",
    "  print('Number of images in {} dataset: {}'.format(group, len(dataset)))\n",
    "  print('Details for image id {} from the {} dataset'.format(\n",
    "      image_overall_index,\n",
    "      group\n",
    "  ))\n",
    "  im, class_oh = dataset[image_overall_index]\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  print('Sample image class: {}'.format(class_oh))\n",
    "\n",
    "  print('\\nVerify the open_img and show_img functions')\n",
    "  print('Open and show image {} from the {}_{} dataset'.format(\n",
    "      image_specific_dataset_index,\n",
    "      group,\n",
    "      class_val\n",
    "  ))\n",
    "  im = dataset.open_img(group, class_val, covid_status, image_specific_dataset_index)\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  dataset.show_img(group, class_val, covid_status, image_specific_dataset_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9CO29iBYHs-"
   },
   "source": [
    "### 2.2.1 Layer 0 Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBI4uwQqYiWI",
    "outputId": "85bd6cde-7de8-4d13-f673-c804d7b07afc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the train dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 5216 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - train_normal, in folder ./dataset/train/normal: 1341 images.\n",
      " - train_infected, in folder ./dataset/train/infected: 3875 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_group = 'train'\n",
    "l0_ld_train = L0_Lung_Dataset(groups = train_group,\n",
    "                              dataset_numbers = binary_dataset_numbers['layer_0'][train_group],\n",
    "                              dataset_paths = binary_dataset_paths['layer_0'][train_group],\n",
    "                              infected_sub_class_numbers = binary_dataset_numbers['layer_1'][train_group])\n",
    "l0_ld_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMz0d7zfY5W7"
   },
   "source": [
    "### 2.2.2 Layer 0 Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4Sju4KFY5p8",
    "outputId": "98d6791a-1db3-407d-f64b-b2e41913b942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the val dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 24 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - val_normal, in folder ./dataset/val/normal: 8 images.\n",
      " - val_infected, in folder ./dataset/val/infected: 16 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_group = 'val'\n",
    "l0_ld_val = L0_Lung_Dataset(groups = val_group,\n",
    "                            dataset_numbers = binary_dataset_numbers['layer_0'][val_group],\n",
    "                            dataset_paths = binary_dataset_paths['layer_0'][val_group],\n",
    "                            infected_sub_class_numbers = binary_dataset_numbers['layer_1'][val_group])\n",
    "l0_ld_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojan7nynZILA"
   },
   "source": [
    "### 2.2.3 Layer 0 Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdxD1NzmZIvq",
    "outputId": "8c7d32f1-846f-409a-8e31-b360cb41dd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the test dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 614 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - test_normal, in folder ./dataset/test/normal: 234 images.\n",
      " - test_infected, in folder ./dataset/test/infected: 380 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_group = 'test'\n",
    "l0_ld_test = L0_Lung_Dataset(groups = test_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_0'][test_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_0'][test_group],\n",
    "                              infected_sub_class_numbers = binary_dataset_numbers['layer_1'][test_group])\n",
    "l0_ld_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRmEfd3Z2ccn"
   },
   "source": [
    "## 2.3 Layer 1 General Dataset object that is custom made for train, val, test to individually use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lWR5VOpK2pan"
   },
   "outputs": [],
   "source": [
    "class L1_Lung_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generic Dataset class for Layer 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, groups, dataset_numbers, dataset_paths):\n",
    "        \"\"\"\n",
    "        Constructor for generic Dataset class for Layer0 - assembles\n",
    "        the important parameters in attributes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        groups : str\n",
    "            Allowed values: train, val, test\n",
    "        dataset_numbers : dict\n",
    "            Count of each class within specified group (e.g. covid, non_covid)\n",
    "        dataset_paths : dict\n",
    "            Path to each class within specified group (infected has 2 sub-class dir)\n",
    "        \"\"\"\n",
    "\n",
    "        self.img_size = (150, 150)\n",
    "        self.classes = {0: 'covid', 1: 'non_covid'}\n",
    "        self.groups = groups\n",
    "        self.dataset_numbers = dataset_numbers\n",
    "        self.dataset_paths = dataset_paths\n",
    "\n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Descriptor function.\n",
    "        Will print details about the dataset when called.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate description\n",
    "        msg = \"This is the {} dataset of the Lung Dataset\".format(self.groups)\n",
    "        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n",
    "        msg += \" in March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for key, val in self.dataset_paths.items():\n",
    "            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n",
    "        print(msg)\n",
    "        \n",
    "    \n",
    "    def open_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'covid' or 'non-covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \n",
    "        Returns loaded image as a normalized Numpy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Asserts checking for consistency in passed parameters\n",
    "        err_msg = \"Error - group_val variable should be set to 'train', 'test' or 'val'.\"\n",
    "        assert group_val in self.groups, err_msg\n",
    "        \n",
    "        err_msg = \"Error - class_val variable should be set to 'covid' or 'non-covid'.\"\n",
    "        assert class_val in self.classes.values(), err_msg     \n",
    "        \n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n",
    "        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n",
    "        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n",
    "        assert isinstance(index_val, int), err_msg\n",
    "        assert index_val >= 0 and index_val <= max_val, err_msg\n",
    "        \n",
    "        # Open file as before\n",
    "        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            im = np.asarray(Image.open(f))/255\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    \n",
    "    def show_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens, then displays image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'covid' or 'non-covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open image\n",
    "        im = self.open_img(group_val, class_val, index_val)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length special method, returns the number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Length function\n",
    "        return sum(self.dataset_numbers.values())\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getitem special method.\n",
    "        \n",
    "        Expects an integer value index, between 0 and len(self) - 1.\n",
    "        \n",
    "        Returns the image and its label as a one hot vector, both\n",
    "        in torch tensor format in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get item special method\n",
    "        first_val = int(list(self.dataset_numbers.values())[0])\n",
    "        if index < first_val:\n",
    "            class_val = 'covid'\n",
    "            label = torch.Tensor([1, 0])\n",
    "        else:\n",
    "            class_val = 'non_covid'\n",
    "            index = index - first_val\n",
    "            label = torch.Tensor([0, 1])\n",
    "\n",
    "        im = self.open_img(self.groups, class_val, index)\n",
    "        im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MB6wqXUN5wMd"
   },
   "outputs": [],
   "source": [
    "def verify_l1_dataset(group,dataset,image_overall_index,class_val,\n",
    "                   image_specific_dataset_index=1):\n",
    "  \"\"\"\n",
    "  Helper function to verify that the classes are implemented correctly\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  group : str\n",
    "      Allowed values: train, val, test\n",
    "  dataset: object\n",
    "      Object instantiated from the class\n",
    "  image_overall_index: int\n",
    "      Overall index in the full dataset across all classes\n",
    "  class_val: str\n",
    "      Image label. Example: covid, non-covid\n",
    "  image_specific_dataset_index : int\n",
    "      image id in the specific nested directory\n",
    "  \"\"\"\n",
    "  print('Verify the special methods __len__ and __get_item__')\n",
    "  print('Number of images in {} dataset: {}'.format(group, len(dataset)))\n",
    "  print('Details for image id {} from the {} dataset'.format(\n",
    "      image_overall_index,\n",
    "      group\n",
    "  ))\n",
    "  im, class_oh = dataset[image_overall_index]\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  print('Sample image class: {}'.format(class_oh))\n",
    "\n",
    "  print('\\nVerify the open_img and show_img functions')\n",
    "  print('Open and show image {} from the {}_{} dataset'.format(\n",
    "      image_specific_dataset_index,\n",
    "      group,\n",
    "      class_val\n",
    "  ))\n",
    "  im = dataset.open_img(group, class_val, image_specific_dataset_index)\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  dataset.show_img(group, class_val, image_specific_dataset_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIeOkWaC2n3U"
   },
   "source": [
    "### 2.3.1 Layer 1 Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McMnU4Jm6X58",
    "outputId": "9379e5db-1023-4da9-e66b-2de0054528b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the train dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 3875 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - train_covid, in folder ./dataset/train/infected/covid: 1345 images.\n",
      " - train_non_covid, in folder ./dataset/train/infected/non-covid: 2530 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_group = 'train'\n",
    "l1_ld_train = L1_Lung_Dataset(groups = train_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_1'][train_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_1'][train_group])\n",
    "l1_ld_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZt-Y09H2gcy"
   },
   "source": [
    "### 2.3.2 Layer 1 Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UP8YEmM48GAs",
    "outputId": "b86ad0d3-5039-41d3-f3b1-788cba8935cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the val dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 16 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - val_covid, in folder ./dataset/val/infected/covid: 8 images.\n",
      " - val_non_covid, in folder ./dataset/val/infected/non-covid: 8 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_group = 'val'\n",
    "l1_ld_val = L1_Lung_Dataset(groups = val_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_1'][val_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_1'][val_group])\n",
    "l1_ld_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSZCUuuS6RLL"
   },
   "source": [
    "### 2.3.3 Layer 1 Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx5IOpZN8Gws",
    "outputId": "a1d3361c-11f1-45ab-bafa-62a48b9173f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the test dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 380 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - test_covid, in folder ./dataset/test/infected/covid: 138 images.\n",
      " - test_non_covid, in folder ./dataset/test/infected/non-covid: 242 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_group = 'test'\n",
    "l1_ld_test = L1_Lung_Dataset(groups = test_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_1'][test_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_1'][test_group])\n",
    "l1_ld_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC14yqAz2vSI"
   },
   "source": [
    "# 3. Creating a data loader object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5YY_qNrFUTw"
   },
   "source": [
    "## 3.1 Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uiftrqf62usb"
   },
   "outputs": [],
   "source": [
    "l0_bs_train = 32\n",
    "l0_bs_test = 32\n",
    "l0_bs_val = 1\n",
    "l0_train_loader = DataLoader(l0_ld_train, batch_size = l0_bs_train, shuffle = True)\n",
    "l0_test_loader = DataLoader(l0_ld_test, batch_size = l0_bs_test, shuffle = True)\n",
    "l0_val_loader = DataLoader(l0_ld_val, batch_size = l0_bs_val, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4Fv6HyVFsfa"
   },
   "source": [
    "## 3.2 Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wpHtBlbSFTZW"
   },
   "outputs": [],
   "source": [
    "l1_bs_train = 32\n",
    "l1_bs_test = 32\n",
    "l1_bs_val = 1\n",
    "l1_train_loader = DataLoader(l1_ld_train, batch_size = l1_bs_train, shuffle = True)\n",
    "l1_test_loader = DataLoader(l1_ld_test, batch_size = l1_bs_test, shuffle = True)\n",
    "l1_val_loader = DataLoader(l1_ld_val, batch_size = l1_bs_val, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x_-1Qe34U5w"
   },
   "source": [
    "# 4. Model\n",
    "\n",
    "https://link.springer.com/article/10.1007/s12652-021-02917-3#Sec9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVfcawPjF5sl"
   },
   "source": [
    "## 4.1 Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-yJ7JTk04XIu"
   },
   "outputs": [],
   "source": [
    "class L0_Net(nn.Module):\n",
    "    def __init__(self, num_layers=1):\n",
    "        super(L0_Net, self).__init__()\n",
    "        # Conv2D: 1 input channel, 4 output channels, 3 by 3 kernel, stride of 1.\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(8, 32, 3, 1)\n",
    "        self.avgpool = nn.AvgPool2d(3)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "        self.fc1 = nn.Linear(16928, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJKx7kXTQYQN",
    "outputId": "3b65b8c6-a923-4f89-f83e-8962961cd577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n"
     ]
    }
   ],
   "source": [
    "# Activate gpu\n",
    "if torch.cuda.is_available():  \n",
    "    print('using GPU')\n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "l0_model = L0_Net().to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoBbl4-OO417",
    "outputId": "f3d2aa22-250a-4198-deea-5bed17428e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 148, 148]             160\n",
      "         Dropout2d-2         [-1, 16, 148, 148]               0\n",
      "              ReLU-3         [-1, 16, 148, 148]               0\n",
      "            Conv2d-4          [-1, 8, 146, 146]           1,160\n",
      "              ReLU-5          [-1, 8, 146, 146]               0\n",
      "         MaxPool2d-6            [-1, 8, 73, 73]               0\n",
      "         Dropout2d-7            [-1, 8, 73, 73]               0\n",
      "            Conv2d-8           [-1, 32, 71, 71]           2,336\n",
      "              ReLU-9           [-1, 32, 71, 71]               0\n",
      "        AvgPool2d-10           [-1, 32, 23, 23]               0\n",
      "        Dropout2d-11           [-1, 32, 23, 23]               0\n",
      "             ReLU-12           [-1, 32, 23, 23]               0\n",
      "           Linear-13                    [-1, 2]          33,858\n",
      "================================================================\n",
      "Total params: 37,514\n",
      "Trainable params: 37,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 14.12\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 14.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(l0_model, (1, 150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUtueamzGHp9"
   },
   "source": [
    "## 4.2 Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "El3FLR03GJ5m"
   },
   "outputs": [],
   "source": [
    "class L1_Net(nn.Module):\n",
    "    def __init__(self, num_layers=1):\n",
    "        super(L1_Net, self).__init__()\n",
    "        # Conv2D: 1 input channel, 4 output channels, 3 by 3 kernel, stride of 1.\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(8, 32, 3, 1)\n",
    "        self.avgpool = nn.AvgPool2d(3)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "        self.fc1 = nn.Linear(16928, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3uSnZgeGKO-",
    "outputId": "af1fa8f1-4e48-4b26-a9a3-30c0892902d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n"
     ]
    }
   ],
   "source": [
    "# Activate gpu\n",
    "if torch.cuda.is_available():  \n",
    "    print('using GPU')\n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "l1_model = L1_Net().to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tRV7PJIGPTH",
    "outputId": "02c17861-2d3b-4165-bcac-46bb06c4cb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 148, 148]             160\n",
      "         Dropout2d-2         [-1, 16, 148, 148]               0\n",
      "              ReLU-3         [-1, 16, 148, 148]               0\n",
      "            Conv2d-4          [-1, 8, 146, 146]           1,160\n",
      "              ReLU-5          [-1, 8, 146, 146]               0\n",
      "         MaxPool2d-6            [-1, 8, 73, 73]               0\n",
      "         Dropout2d-7            [-1, 8, 73, 73]               0\n",
      "            Conv2d-8           [-1, 32, 71, 71]           2,336\n",
      "              ReLU-9           [-1, 32, 71, 71]               0\n",
      "        AvgPool2d-10           [-1, 32, 23, 23]               0\n",
      "        Dropout2d-11           [-1, 32, 23, 23]               0\n",
      "             ReLU-12           [-1, 32, 23, 23]               0\n",
      "           Linear-13                    [-1, 2]          33,858\n",
      "================================================================\n",
      "Total params: 37,514\n",
      "Trainable params: 37,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 14.12\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 14.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(l1_model, (1, 150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1E4MDvTLdnP"
   },
   "source": [
    "# 5. Training the model\n",
    "\n",
    "Reference material: [Towards data science: PyTorch [Tabular] â€” Multiclass Classification](https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "98hO2OLpLdRK"
   },
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.1 GridSearch for Layer 0\n",
    "\n",
    "## Hyperparameters \n",
    "epochs = [5, 10]\n",
    "lr = [0.0001, 0.00001]\n",
    "scheduler_gamma = [0.1, 0.001]\n",
    "weight_decay = [0, 0.01]\n",
    "Optimizer = Adam, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_L0(epochs, lr, scheduler_gamma, weight_decay, use_adam= True,log_path='../tuning_layer_0_hyperparameters.log'):\n",
    "    \n",
    "    # Activate gpu\n",
    "    if torch.cuda.is_available():  \n",
    "        print('using GPU')\n",
    "        device = \"cuda:0\" \n",
    "    else:  \n",
    "        device = \"cpu\"\n",
    "        \n",
    "    # Load a fresh network\n",
    "    l0_model = L0_Net().to(torch.device(device))\n",
    "    \n",
    "    # setup\n",
    "    l0_class_weights = torch.tensor([2.83, 1.0]).to(torch.device(device))\n",
    "    criterion = nn.CrossEntropyLoss(l0_class_weights)\n",
    "    if use_adam:\n",
    "        optimizer = optim.Adam(l0_model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.AdamW(l0_model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=scheduler_gamma)\n",
    "    \n",
    "    start = time.time()\n",
    "    start_model_time = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    \n",
    "    # Save log for hyperparameters\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(\"{} : Training L0 model - epochs {} - lr {} - scheduler_gamma {} - weight_decay - {} - use_adam {} \\n\".format(start_model_time, epochs, lr, scheduler_gamma, weight_decay, use_adam))\n",
    "    \n",
    "    l0_accuracy_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "    l0_loss_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_acc = 0\n",
    "\n",
    "        l0_model.train()\n",
    "        for batch_idx, (X_train_batch, y_train_batch) in enumerate(l0_train_loader):\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = l0_model.forward(X_train_batch)\n",
    "            train_loss  = criterion(output, torch.max(y_train_batch, 1)[1])\n",
    "            train_acc = multi_acc(output, torch.max(y_train_batch, 1)[1])\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step(e + batch_idx / len(l0_train_loader))\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            train_epoch_acc += train_acc.item()\n",
    "            \n",
    "        # update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # testing\n",
    "        with torch.no_grad():\n",
    "            test_epoch_loss = 0\n",
    "            test_epoch_acc = 0\n",
    "            l0_model.eval()\n",
    "            for X_test_batch, y_test_batch in l0_test_loader:\n",
    "                X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "\n",
    "                y_test_pred = l0_model.forward(X_test_batch)\n",
    "\n",
    "                test_loss = criterion(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "                test_acc = multi_acc(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "\n",
    "                test_epoch_loss += test_loss.item()\n",
    "                test_epoch_acc += test_acc.item()\n",
    "\n",
    "\n",
    "        # averaged\n",
    "        train_epoch_loss = train_epoch_loss/len(l0_train_loader)\n",
    "        train_epoch_acc = train_epoch_acc/len(l0_train_loader)\n",
    "        test_epoch_loss = test_epoch_loss/len(l0_test_loader)\n",
    "        test_epoch_acc = test_epoch_acc/len(l0_test_loader)\n",
    "\n",
    "        # The step number corresponds to the number of batches seen\n",
    "        now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        print(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now),\n",
    "          \"Training Loss: {:.4f} - \".format(train_epoch_loss),\n",
    "          \"Training Accuracy: {:.4f} -\".format(train_epoch_acc),\n",
    "          \"Test Loss: {:.4f} - \".format(test_epoch_loss),\n",
    "          \"Test Accuracy: {:.4f}\".format(test_epoch_acc))\n",
    "        l0_model.train()\n",
    "        \n",
    "        # save the logs\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now))\n",
    "            f.write(\"Training Loss: {:.4f} - \".format(train_epoch_loss))\n",
    "            f.write(\"Training Accuracy: {:.4f} - \".format(train_epoch_acc))\n",
    "            f.write(\"Test Loss: {:.4f} - \".format(test_epoch_loss))\n",
    "            f.write(\"Test Accuracy: {:.4f}\\n\\n\".format(test_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 12:16:24 -  Training Loss: 0.6263 -  Training Accuracy: 0.6727 - Test Loss: 0.4531 -  Test Accuracy: 0.7885\n",
      "Epoch: 2/5 - 21/03/2021 12:16:32 -  Training Loss: 0.3007 -  Training Accuracy: 0.8846 - Test Loss: 0.5790 -  Test Accuracy: 0.8099\n",
      "Epoch: 3/5 - 21/03/2021 12:16:41 -  Training Loss: 0.2146 -  Training Accuracy: 0.9187 - Test Loss: 0.7785 -  Test Accuracy: 0.7964\n",
      "Epoch: 4/5 - 21/03/2021 12:16:49 -  Training Loss: 0.1847 -  Training Accuracy: 0.9325 - Test Loss: 0.9860 -  Test Accuracy: 0.7792\n",
      "Epoch: 5/5 - 21/03/2021 12:16:57 -  Training Loss: 0.1790 -  Training Accuracy: 0.9321 - Test Loss: 0.8609 -  Test Accuracy: 0.8010\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 12:17:05 -  Training Loss: 0.6704 -  Training Accuracy: 0.6336 - Test Loss: 0.6007 -  Test Accuracy: 0.8250\n",
      "Epoch: 2/10 - 21/03/2021 12:17:13 -  Training Loss: 0.3721 -  Training Accuracy: 0.8809 - Test Loss: 0.6952 -  Test Accuracy: 0.7828\n",
      "Epoch: 3/10 - 21/03/2021 12:17:22 -  Training Loss: 0.2100 -  Training Accuracy: 0.9233 - Test Loss: 0.6853 -  Test Accuracy: 0.7927\n",
      "Epoch: 4/10 - 21/03/2021 12:17:30 -  Training Loss: 0.1832 -  Training Accuracy: 0.9373 - Test Loss: 0.6313 -  Test Accuracy: 0.8172\n",
      "Epoch: 5/10 - 21/03/2021 12:17:38 -  Training Loss: 0.1708 -  Training Accuracy: 0.9360 - Test Loss: 0.9483 -  Test Accuracy: 0.7896\n",
      "Epoch: 6/10 - 21/03/2021 12:17:47 -  Training Loss: 0.1584 -  Training Accuracy: 0.9421 - Test Loss: 0.8858 -  Test Accuracy: 0.7724\n",
      "Epoch: 7/10 - 21/03/2021 12:17:55 -  Training Loss: 0.1538 -  Training Accuracy: 0.9413 - Test Loss: 0.7810 -  Test Accuracy: 0.8047\n",
      "Epoch: 8/10 - 21/03/2021 12:18:04 -  Training Loss: 0.1490 -  Training Accuracy: 0.9456 - Test Loss: 0.8772 -  Test Accuracy: 0.7995\n",
      "Epoch: 9/10 - 21/03/2021 12:18:12 -  Training Loss: 0.1555 -  Training Accuracy: 0.9471 - Test Loss: 0.8599 -  Test Accuracy: 0.7995\n",
      "Epoch: 10/10 - 21/03/2021 12:18:21 -  Training Loss: 0.1506 -  Training Accuracy: 0.9436 - Test Loss: 0.8478 -  Test Accuracy: 0.7995\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 12:18:29 -  Training Loss: 0.6907 -  Training Accuracy: 0.5631 - Test Loss: 0.6971 -  Test Accuracy: 0.6208\n",
      "Epoch: 2/10 - 21/03/2021 12:18:38 -  Training Loss: 0.6784 -  Training Accuracy: 0.7546 - Test Loss: 0.6888 -  Test Accuracy: 0.6323\n",
      "Epoch: 3/10 - 21/03/2021 12:18:46 -  Training Loss: 0.6530 -  Training Accuracy: 0.8035 - Test Loss: 0.6609 -  Test Accuracy: 0.8104\n",
      "Epoch: 4/10 - 21/03/2021 12:18:55 -  Training Loss: 0.6055 -  Training Accuracy: 0.8284 - Test Loss: 0.6092 -  Test Accuracy: 0.8130\n",
      "Epoch: 5/10 - 21/03/2021 12:19:03 -  Training Loss: 0.5418 -  Training Accuracy: 0.8715 - Test Loss: 0.5463 -  Test Accuracy: 0.8214\n",
      "Epoch: 6/10 - 21/03/2021 12:19:12 -  Training Loss: 0.5005 -  Training Accuracy: 0.8746 - Test Loss: 0.5484 -  Test Accuracy: 0.8229\n",
      "Epoch: 7/10 - 21/03/2021 12:19:21 -  Training Loss: 0.4918 -  Training Accuracy: 0.8733 - Test Loss: 0.5442 -  Test Accuracy: 0.8229\n",
      "Epoch: 8/10 - 21/03/2021 12:19:30 -  Training Loss: 0.4830 -  Training Accuracy: 0.8792 - Test Loss: 0.5370 -  Test Accuracy: 0.8271\n",
      "Epoch: 9/10 - 21/03/2021 12:19:39 -  Training Loss: 0.4812 -  Training Accuracy: 0.8683 - Test Loss: 0.5416 -  Test Accuracy: 0.8245\n",
      "Epoch: 10/10 - 21/03/2021 12:19:47 -  Training Loss: 0.4786 -  Training Accuracy: 0.8823 - Test Loss: 0.5269 -  Test Accuracy: 0.8245\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 12:19:56 -  Training Loss: 0.6009 -  Training Accuracy: 0.7032 - Test Loss: 0.4158 -  Test Accuracy: 0.7901\n",
      "Epoch: 2/10 - 21/03/2021 12:20:06 -  Training Loss: 0.3071 -  Training Accuracy: 0.8873 - Test Loss: 0.6073 -  Test Accuracy: 0.8078\n",
      "Epoch: 3/10 - 21/03/2021 12:20:15 -  Training Loss: 0.2284 -  Training Accuracy: 0.9149 - Test Loss: 0.8325 -  Test Accuracy: 0.7729\n",
      "Epoch: 4/10 - 21/03/2021 12:20:24 -  Training Loss: 0.1916 -  Training Accuracy: 0.9298 - Test Loss: 0.8002 -  Test Accuracy: 0.8010\n",
      "Epoch: 5/10 - 21/03/2021 12:20:33 -  Training Loss: 0.1897 -  Training Accuracy: 0.9304 - Test Loss: 1.1521 -  Test Accuracy: 0.7542\n",
      "Epoch: 6/10 - 21/03/2021 12:20:42 -  Training Loss: 0.1838 -  Training Accuracy: 0.9502 - Test Loss: 1.1840 -  Test Accuracy: 0.7521\n",
      "Epoch: 7/10 - 21/03/2021 12:20:51 -  Training Loss: 0.1844 -  Training Accuracy: 0.9434 - Test Loss: 1.0818 -  Test Accuracy: 0.7620\n",
      "Epoch: 8/10 - 21/03/2021 12:21:01 -  Training Loss: 0.1751 -  Training Accuracy: 0.9461 - Test Loss: 1.0394 -  Test Accuracy: 0.7667\n",
      "Epoch: 9/10 - 21/03/2021 12:21:10 -  Training Loss: 0.1725 -  Training Accuracy: 0.9457 - Test Loss: 1.0535 -  Test Accuracy: 0.7646\n",
      "Epoch: 10/10 - 21/03/2021 12:21:19 -  Training Loss: 0.1751 -  Training Accuracy: 0.9434 - Test Loss: 1.0144 -  Test Accuracy: 0.7594\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 12:21:28 -  Training Loss: 0.5920 -  Training Accuracy: 0.7182 - Test Loss: 0.4342 -  Test Accuracy: 0.8099\n",
      "Epoch: 2/10 - 21/03/2021 12:21:38 -  Training Loss: 0.2912 -  Training Accuracy: 0.8905 - Test Loss: 0.4236 -  Test Accuracy: 0.8354\n",
      "Epoch: 3/10 - 21/03/2021 12:21:47 -  Training Loss: 0.2150 -  Training Accuracy: 0.9212 - Test Loss: 0.6126 -  Test Accuracy: 0.8182\n",
      "Epoch: 4/10 - 21/03/2021 12:21:56 -  Training Loss: 0.1954 -  Training Accuracy: 0.9287 - Test Loss: 0.7072 -  Test Accuracy: 0.8109\n",
      "Epoch: 5/10 - 21/03/2021 12:22:05 -  Training Loss: 0.1816 -  Training Accuracy: 0.9367 - Test Loss: 0.8326 -  Test Accuracy: 0.7833\n",
      "Epoch: 6/10 - 21/03/2021 12:22:14 -  Training Loss: 0.1622 -  Training Accuracy: 0.9400 - Test Loss: 0.8638 -  Test Accuracy: 0.7833\n",
      "Epoch: 7/10 - 21/03/2021 12:22:23 -  Training Loss: 0.1618 -  Training Accuracy: 0.9421 - Test Loss: 0.8619 -  Test Accuracy: 0.7969\n",
      "Epoch: 8/10 - 21/03/2021 12:22:33 -  Training Loss: 0.1628 -  Training Accuracy: 0.9408 - Test Loss: 0.9485 -  Test Accuracy: 0.7802\n",
      "Epoch: 9/10 - 21/03/2021 12:22:42 -  Training Loss: 0.1575 -  Training Accuracy: 0.9410 - Test Loss: 1.0065 -  Test Accuracy: 0.7786\n",
      "Epoch: 10/10 - 21/03/2021 12:22:52 -  Training Loss: 0.1640 -  Training Accuracy: 0.9400 - Test Loss: 0.9068 -  Test Accuracy: 0.7833\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 12:23:01 -  Training Loss: 0.6320 -  Training Accuracy: 0.6622 - Test Loss: 0.4599 -  Test Accuracy: 0.8104\n",
      "Epoch: 2/10 - 21/03/2021 12:23:11 -  Training Loss: 0.3145 -  Training Accuracy: 0.8825 - Test Loss: 0.6756 -  Test Accuracy: 0.7969\n",
      "Epoch: 3/10 - 21/03/2021 12:23:21 -  Training Loss: 0.2200 -  Training Accuracy: 0.9185 - Test Loss: 0.4908 -  Test Accuracy: 0.8276\n",
      "Epoch: 4/10 - 21/03/2021 12:23:30 -  Training Loss: 0.2035 -  Training Accuracy: 0.9229 - Test Loss: 0.7704 -  Test Accuracy: 0.7948\n",
      "Epoch: 5/10 - 21/03/2021 12:23:39 -  Training Loss: 0.1831 -  Training Accuracy: 0.9250 - Test Loss: 0.8991 -  Test Accuracy: 0.7875\n",
      "Epoch: 6/10 - 21/03/2021 12:23:49 -  Training Loss: 0.1684 -  Training Accuracy: 0.9385 - Test Loss: 0.9428 -  Test Accuracy: 0.7760\n",
      "Epoch: 7/10 - 21/03/2021 12:23:58 -  Training Loss: 0.1654 -  Training Accuracy: 0.9388 - Test Loss: 0.8555 -  Test Accuracy: 0.7818\n",
      "Epoch: 8/10 - 21/03/2021 12:24:07 -  Training Loss: 0.1676 -  Training Accuracy: 0.9402 - Test Loss: 0.9311 -  Test Accuracy: 0.7859\n",
      "Epoch: 9/10 - 21/03/2021 12:24:17 -  Training Loss: 0.1596 -  Training Accuracy: 0.9419 - Test Loss: 0.9534 -  Test Accuracy: 0.7823\n",
      "Epoch: 10/10 - 21/03/2021 12:24:26 -  Training Loss: 0.1639 -  Training Accuracy: 0.9413 - Test Loss: 0.7604 -  Test Accuracy: 0.7995\n"
     ]
    }
   ],
   "source": [
    "# epochs\n",
    "train_model_L0(epochs= 5, lr=0.0001, scheduler_gamma=0.1, weight_decay=0)\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.1, weight_decay=0)\n",
    "\n",
    "# learning rate\n",
    "train_model_L0(epochs= 10, lr=0.00001, scheduler_gamma=0.1, weight_decay=0)\n",
    "\n",
    "# scheduler gamma\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.001, weight_decay=0)\n",
    "\n",
    "# weight decay\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.1, weight_decay=0.01)\n",
    "\n",
    "# AdamW\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.1, weight_decay=0, use_adam= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRYDiwdsL4vB"
   },
   "source": [
    "## 5.2 Layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.1 GridSearch for Layer 1\n",
    "hyperparameters\n",
    "'epochs': [5, 10] 'lr': [0.0001, 0.00001] 'scheduler_gamma': [0.1, 0.001] 'l1_lambda': [0.5, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_L1(epochs, lr, scheduler_gamma, l1_lambda, log_path='../layer_1_gridsearch.log'):\n",
    "    \n",
    "    # Activate gpu\n",
    "    if torch.cuda.is_available():  \n",
    "        print('using GPU')\n",
    "        device = \"cuda:0\" \n",
    "    else:  \n",
    "        device = \"cpu\"\n",
    "        \n",
    "    # Load a fresh network\n",
    "    l1_model = L1_Net().to(torch.device(device))\n",
    "    \n",
    "    # setup\n",
    "    weight_decay = 0.00001\n",
    "    l1_class_weights = torch.tensor([2.83, 1.0]).to(torch.device(device))\n",
    "    criterion = nn.CrossEntropyLoss(l0_class_weights)\n",
    "    optimizer = optim.AdamW(l1_model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=scheduler_gamma)\n",
    "    \n",
    "    start = time.time()\n",
    "    start_model_time = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    \n",
    "    L1_reg = torch.tensor(0., requires_grad=True)\n",
    "    for name, param in l1_model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            L1_reg = L1_reg + torch.norm(param, 1)\n",
    "    \n",
    "    # Save log for hyperparameters\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(\"{} : Training L1 model - epochs {} - lr {} - scheduler_gamma {} - l1_lambda - {} \\n\".format(start_model_time, epochs, lr, scheduler_gamma, l1_lambda))\n",
    "    \n",
    "    l1_accuracy_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "    l1_loss_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_acc = 0\n",
    "\n",
    "        l1_model.train()\n",
    "        for batch_idx, (X_train_batch, y_train_batch) in enumerate(l1_train_loader):\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = l1_model.forward(X_train_batch)\n",
    "            train_loss  = criterion(output, torch.max(y_train_batch, 1)[1])\n",
    "            train_acc = multi_acc(output, torch.max(y_train_batch, 1)[1])\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            train_epoch_acc += train_acc.item()\n",
    "            \n",
    "        # update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # testing\n",
    "        with torch.no_grad():\n",
    "            test_epoch_loss = 0\n",
    "            test_epoch_acc = 0\n",
    "            l1_model.eval()\n",
    "            for X_test_batch, y_test_batch in l1_test_loader:\n",
    "                X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "\n",
    "                y_test_pred = l1_model.forward(X_test_batch)\n",
    "\n",
    "                test_loss = criterion(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "                test_acc = multi_acc(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "\n",
    "                test_epoch_loss += test_loss.item()\n",
    "                test_epoch_acc += test_acc.item()\n",
    "\n",
    "\n",
    "        # averaged\n",
    "        train_epoch_loss = train_epoch_loss/len(l1_train_loader)\n",
    "        train_epoch_acc = train_epoch_acc/len(l1_train_loader)\n",
    "        test_epoch_loss = test_epoch_loss/len(l1_test_loader)\n",
    "        test_epoch_acc = test_epoch_acc/len(l1_test_loader)\n",
    "\n",
    "        # The step number corresponds to the number of batches seen\n",
    "        now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        print(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now),\n",
    "          \"Training Loss: {:.4f} - \".format(train_epoch_loss),\n",
    "          \"Training Accuracy: {:.4f}\".format(train_epoch_acc),\n",
    "          \"Test Loss: {:.4f} - \".format(test_epoch_loss),\n",
    "          \"Test Accuracy: {:.4f}\".format(test_epoch_acc))\n",
    "        l1_model.train()\n",
    "\n",
    "        # Epoch metrics\n",
    "        l1_loss_stats_epoch['train'].append(train_epoch_loss)\n",
    "        l1_loss_stats_epoch['test'].append(test_epoch_loss)\n",
    "        l1_loss_stats_epoch['epoch'].append(e+1)\n",
    "        l1_accuracy_stats_epoch['train'].append(train_epoch_acc)\n",
    "        l1_accuracy_stats_epoch['test'].append(test_epoch_acc)\n",
    "        l1_accuracy_stats_epoch['epoch'].append(e+1)\n",
    "\n",
    "        # save the logs\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now))\n",
    "            f.write(\"Training Loss: {:.4f} - \".format(train_epoch_loss))\n",
    "            f.write(\"Training Accuracy: {:.4f} - \".format(train_epoch_acc))\n",
    "            f.write(\"Test Loss: {:.4f} - \".format(test_epoch_loss))\n",
    "            f.write(\"Test Accuracy: {:.4f}\\\\n\".format(test_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs\n",
    "train_model_L1(epochs= 5, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "\n",
    "# learning rate\n",
    "train_model_L1(epochs= 5, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 10, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "\n",
    "# scheduler gamma\n",
    "train_model_L1(epochs= 5, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 5, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 10, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "\n",
    "# l1 lambda\n",
    "train_model_L1(epochs= 5, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 5, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 10, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 5, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 5, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 10, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.01)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "custom_dataset_dataloader_cascade.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
