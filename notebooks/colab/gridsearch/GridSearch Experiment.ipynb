{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moral-rebound"
   },
   "source": [
    "# Boilerplate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "crude-waste"
   },
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pillow\n",
    "from PIL import Image\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "# Misc\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4gBSNDrcfGl"
   },
   "source": [
    "# 1. Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcHbRtuHcd-N",
    "outputId": "70dc59a9-e75b-4543-a2fd-1ba711554312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path '50.039-Deep-Learning' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b data https://github.com/Oxiang/50.039-Deep-Learning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3ElMDwpU831",
    "outputId": "87f3eaa8-5be1-4af9-f5b6-26a6a4181907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "tree is already the newest version (1.7.0-5).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4-h2B3OVCRe",
    "outputId": "0e54a787-30a7-45d0-8a7e-e8d8317642f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sceps\\OneDrive\\Personal Folder\\SUTD Deep Learning\\dl boiler\\50.039-Deep-Learning\\notebooks\\colab\\50.039-Deep-Learning\n"
     ]
    }
   ],
   "source": [
    "cd 50.039-Deep-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DW2ZD2afqdmF",
    "outputId": "bc49a72c-29e8-4a7a-859d-48f73b30dec0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "├── test\n",
      "│   ├── infected\n",
      "│   │   ├── covid\n",
      "│   │   └── non-covid\n",
      "│   └── normal\n",
      "├── train\n",
      "│   ├── infected\n",
      "│   │   ├── covid\n",
      "│   │   └── non-covid\n",
      "│   └── normal\n",
      "└── val\n",
      "    ├── infected\n",
      "    │   ├── covid\n",
      "    │   └── non-covid\n",
      "    └── normal\n",
      "\n",
      "15 directories\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "(\n",
    "tree dataset -d\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NZhr10rHVlIj"
   },
   "outputs": [],
   "source": [
    "classes_n_c = {0: 'normal', 1: 'infected'}\n",
    "classes_inc_ic = {0: 'infected_non_covid', 1: 'infected_covid'}\n",
    "groups = ['train', 'test', 'val']\n",
    "dataset_numbers = {\n",
    "    'train_normal': 1341,\n",
    "    'train_infected_non_covid': 2530,\n",
    "    'train_infected_covid': 1345,\n",
    "    'val_normal': 8,\n",
    "    'val_infected_non_covid': 8,\n",
    "    'val_infected_covid': 8,    \n",
    "    'test_normal': 234,\n",
    "    'test_infected_non_covid': 242,\n",
    "    'test_infected_covid': 138,\n",
    "}\n",
    "dataset_paths = {\n",
    "    'train_normal': './dataset/train/normal/',\n",
    "    'train_infected_non_covid': './dataset/train/infected/non-covid/',\n",
    "    'train_infected_covid': './dataset/train/infected/covid/',\n",
    "    'val_normal': './dataset/val/normal/',\n",
    "    'val_infected_non_covid': './dataset/val/infected/non-covid/',\n",
    "    'val_infected_covid': './dataset/val/infected/covid/',    \n",
    "    'test_normal': './dataset/test/normal/',\n",
    "    'test_infected_non_covid': './dataset/test/infected/non-covid/',\n",
    "    'test_infected_covid': './dataset/test/infected/covid/',    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kakruEOWFn2"
   },
   "source": [
    "View one of the images and its properties. These images consist of a Numpy array, with values ranging between 0 and 255. These values will be normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jcs9foiNXKY1"
   },
   "source": [
    "# 2. Creating a Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pyf61XksuJjY"
   },
   "source": [
    "## 2.1 Common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1Z0B8tOLuI-D"
   },
   "outputs": [],
   "source": [
    "binary_dataset_paths = {\n",
    "    'layer_0': {\n",
    "        'train': {\n",
    "            'train_normal':'./dataset/train/normal',\n",
    "            'train_infected': './dataset/train/infected'\n",
    "        },\n",
    "        'val': {\n",
    "            'val_normal':'./dataset/val/normal',\n",
    "            'val_infected': './dataset/val/infected'\n",
    "        },\n",
    "        'test': {\n",
    "            'test_normal':'./dataset/test/normal',\n",
    "            'test_infected': './dataset/test/infected'\n",
    "        }\n",
    "    },\n",
    "    'layer_1':{\n",
    "        'train': {\n",
    "            'train_covid': './dataset/train/infected/covid',\n",
    "            'train_non_covid' : './dataset/train/infected/non-covid'\n",
    "        },\n",
    "        'val': {\n",
    "            'val_covid': './dataset/val/infected/covid',\n",
    "            'val_non_covid' : './dataset/val/infected/non-covid'\n",
    "        },\n",
    "        'test': {\n",
    "            'test_covid': './dataset/test/infected/covid',\n",
    "            'test_non_covid' : './dataset/test/infected/non-covid'            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "binary_dataset_numbers = {\n",
    "    'layer_0': {\n",
    "        'train': {\n",
    "            'train_normal': 1341,\n",
    "            'train_infected': 3875\n",
    "        },\n",
    "        'val': {\n",
    "            'val_normal': 8,\n",
    "            'val_infected': 16\n",
    "        },\n",
    "        'test': {\n",
    "            'test_normal': 234,\n",
    "            'test_infected': 380\n",
    "        }\n",
    "    },\n",
    "    'layer_1':{\n",
    "        'train': {\n",
    "            'train_covid': 1345,\n",
    "            'train_non_covid' : 2530\n",
    "        },\n",
    "        'val': {\n",
    "            'val_covid': 8,\n",
    "            'val_non_covid': 8\n",
    "        },\n",
    "        'test': {\n",
    "            'test_covid': 138,\n",
    "            'test_non_covid': 242            \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKLCcIvxXLHu"
   },
   "source": [
    "## 2.2 Layer 0 General Dataset object that is custom made for train, val, test to individually use\n",
    "\n",
    "length method ( __ len __ )\n",
    "\n",
    "> return the number of images present in the dataset\n",
    "\n",
    "getitem method ( __ getitem __ )\n",
    "\n",
    "> fetch an image and its label, using a single index value. Returns the image, along with a one-hot vector corresponding to the class of the object. Both returned parameters will be torch tensors.\n",
    "- [1, 0] for normal class\n",
    "- [0, 1] for infected class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LtNXQwKbXNfY"
   },
   "outputs": [],
   "source": [
    "class L0_Lung_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generic Dataset class for Layer 0\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, groups, dataset_numbers, dataset_paths, infected_sub_class_numbers):\n",
    "        \"\"\"\n",
    "        Constructor for generic Dataset class for Layer0 - assembles\n",
    "        the important parameters in attributes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        groups : str\n",
    "            Allowed values: train, val, test\n",
    "        dataset_numbers : dict\n",
    "            Count of each class within specified group (e.g. normal, infected)\n",
    "        dataset_paths : dict\n",
    "            Path to each class within specified group (infected has 2 sub-class dir)\n",
    "        \"\"\"\n",
    "\n",
    "        self.img_size = (150, 150)\n",
    "        self.classes = { 0: 'normal', 1: 'infected' }\n",
    "        self.covid_status = {0: '', 1: 'covid', 2: 'non-covid'} \n",
    "        self.groups = groups\n",
    "        self.dataset_numbers = dataset_numbers\n",
    "        self.dataset_paths = dataset_paths\n",
    "        self.infected_sub_class_numbers = infected_sub_class_numbers\n",
    "\n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Descriptor function.\n",
    "        Will print details about the dataset when called.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate description\n",
    "        msg = \"This is the {} dataset of the Lung Dataset\".format(self.groups)\n",
    "        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n",
    "        msg += \" in March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for key, val in self.dataset_paths.items():\n",
    "            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n",
    "        print(msg)\n",
    "        \n",
    "    \n",
    "    def open_img(self, group_val, class_val, covid_status, index_val):\n",
    "        \"\"\"\n",
    "        Opens image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal' or 'infected_non_covid' or 'infected_covid'.\n",
    "        - covid_status should take values in '', 'covid' or 'non_covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \n",
    "        Returns loaded image as a normalized Numpy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Asserts checking for consistency in passed parameters\n",
    "        err_msg = \"Error - group_val variable should be set to 'train', 'test' or 'val'.\"\n",
    "        assert group_val in self.groups, err_msg\n",
    "        \n",
    "        err_msg = \"Error - class_val variable should be set to 'normal' or 'infected_non_covid' or 'infected_covid.\"\n",
    "        assert class_val in self.classes.values(), err_msg\n",
    "\n",
    "        err_msg = \"Error - covid_status variable should be set to '', 'covid' or 'non-covid'.\"\n",
    "        assert covid_status in self.covid_status.values(), err_msg\n",
    "        \n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n",
    "        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n",
    "        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n",
    "        assert isinstance(index_val, int), err_msg\n",
    "        assert index_val >= 0 and index_val <= max_val, err_msg\n",
    "        \n",
    "        # 'normal' - example path: /dataset/train/normal/1.jpg\n",
    "        if covid_status == \"\":\n",
    "            path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n",
    "        # 'covid' or 'non_covid' - example path: './dataset/train/infected/covid/1.jpg',\n",
    "        else:\n",
    "            path_to_file = '{}/{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], covid_status, index_val)\n",
    "\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            # Convert to Numpy array and normalize pixel values by dividing by 255.\n",
    "            im = np.asarray(Image.open(f))/255\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    \n",
    "    def show_img(self, group_val, class_val, covid_status, index_val):\n",
    "        \"\"\"\n",
    "        Opens, then displays image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'normal' or 'infected'.\n",
    "        - covid_status should take values in '', 'covid' or 'non-covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open image\n",
    "        im = self.open_img(group_val, class_val, covid_status, index_val)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length special method, returns the number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Length function\n",
    "        return sum(self.dataset_numbers.values())\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getitem special method.\n",
    "        \n",
    "        Expects an integer value index, between 0 and len(self) - 1.\n",
    "        \n",
    "        Returns the image and its label as a one hot vector, both\n",
    "        in torch tensor format in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get item special method\n",
    "        first_val = int(list(self.dataset_numbers.values())[0])\n",
    "        if index < first_val:\n",
    "            class_val = 'normal'\n",
    "            label = torch.Tensor([1, 0])\n",
    "            covid_status = \"\"\n",
    "        else:\n",
    "            class_val = 'infected'\n",
    "            index = index - first_val\n",
    "            label = torch.Tensor([0, 1])\n",
    "            infected_covid_numbers = int(list(self.infected_sub_class_numbers.values())[0]) # covid\n",
    "            if index < infected_covid_numbers:\n",
    "                class_val = 'infected'\n",
    "                covid_status = 'covid'\n",
    "            else:\n",
    "                class_val = 'infected'\n",
    "                index = index - infected_covid_numbers\n",
    "                covid_status = 'non-covid'\n",
    "        im = self.open_img(self.groups, class_val, covid_status, index)\n",
    "        im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V714D12V5qgY"
   },
   "outputs": [],
   "source": [
    "def verify_l0_dataset(group,dataset,image_overall_index,class_val,covid_status,\n",
    "                   image_specific_dataset_index=1):\n",
    "  \"\"\"\n",
    "  Helper function to verify that the classes are implemented correctly\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  group : str\n",
    "      Allowed values: train, val, test\n",
    "  dataset: object\n",
    "      Object instantiated from the class\n",
    "  image_overall_index: int\n",
    "      Overall index in the full dataset across all classes\n",
    "  class_val: str\n",
    "      Image label. Example: normal, infected\n",
    "  covid_status: str\n",
    "      If class_val is 'infected', set this to either 'covid' or 'non-covid'\n",
    "  image_specific_dataset_index : int\n",
    "      image id in the specific nested directory\n",
    "  \"\"\"\n",
    "  print('Verify the special methods __len__ and __get_item__')\n",
    "  print('Number of images in {} dataset: {}'.format(group, len(dataset)))\n",
    "  print('Details for image id {} from the {} dataset'.format(\n",
    "      image_overall_index,\n",
    "      group\n",
    "  ))\n",
    "  im, class_oh = dataset[image_overall_index]\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  print('Sample image class: {}'.format(class_oh))\n",
    "\n",
    "  print('\\nVerify the open_img and show_img functions')\n",
    "  print('Open and show image {} from the {}_{} dataset'.format(\n",
    "      image_specific_dataset_index,\n",
    "      group,\n",
    "      class_val\n",
    "  ))\n",
    "  im = dataset.open_img(group, class_val, covid_status, image_specific_dataset_index)\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  dataset.show_img(group, class_val, covid_status, image_specific_dataset_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9CO29iBYHs-"
   },
   "source": [
    "### 2.2.1 Layer 0 Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBI4uwQqYiWI",
    "outputId": "85bd6cde-7de8-4d13-f673-c804d7b07afc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the train dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 5216 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - train_normal, in folder ./dataset/train/normal: 1341 images.\n",
      " - train_infected, in folder ./dataset/train/infected: 3875 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_group = 'train'\n",
    "l0_ld_train = L0_Lung_Dataset(groups = train_group,\n",
    "                              dataset_numbers = binary_dataset_numbers['layer_0'][train_group],\n",
    "                              dataset_paths = binary_dataset_paths['layer_0'][train_group],\n",
    "                              infected_sub_class_numbers = binary_dataset_numbers['layer_1'][train_group])\n",
    "l0_ld_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMz0d7zfY5W7"
   },
   "source": [
    "### 2.2.2 Layer 0 Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4Sju4KFY5p8",
    "outputId": "98d6791a-1db3-407d-f64b-b2e41913b942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the val dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 24 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - val_normal, in folder ./dataset/val/normal: 8 images.\n",
      " - val_infected, in folder ./dataset/val/infected: 16 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_group = 'val'\n",
    "l0_ld_val = L0_Lung_Dataset(groups = val_group,\n",
    "                            dataset_numbers = binary_dataset_numbers['layer_0'][val_group],\n",
    "                            dataset_paths = binary_dataset_paths['layer_0'][val_group],\n",
    "                            infected_sub_class_numbers = binary_dataset_numbers['layer_1'][val_group])\n",
    "l0_ld_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojan7nynZILA"
   },
   "source": [
    "### 2.2.3 Layer 0 Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdxD1NzmZIvq",
    "outputId": "8c7d32f1-846f-409a-8e31-b360cb41dd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the test dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 614 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - test_normal, in folder ./dataset/test/normal: 234 images.\n",
      " - test_infected, in folder ./dataset/test/infected: 380 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_group = 'test'\n",
    "l0_ld_test = L0_Lung_Dataset(groups = test_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_0'][test_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_0'][test_group],\n",
    "                              infected_sub_class_numbers = binary_dataset_numbers['layer_1'][test_group])\n",
    "l0_ld_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRmEfd3Z2ccn"
   },
   "source": [
    "## 2.3 Layer 1 General Dataset object that is custom made for train, val, test to individually use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lWR5VOpK2pan"
   },
   "outputs": [],
   "source": [
    "class L1_Lung_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generic Dataset class for Layer 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, groups, dataset_numbers, dataset_paths):\n",
    "        \"\"\"\n",
    "        Constructor for generic Dataset class for Layer0 - assembles\n",
    "        the important parameters in attributes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        groups : str\n",
    "            Allowed values: train, val, test\n",
    "        dataset_numbers : dict\n",
    "            Count of each class within specified group (e.g. covid, non_covid)\n",
    "        dataset_paths : dict\n",
    "            Path to each class within specified group (infected has 2 sub-class dir)\n",
    "        \"\"\"\n",
    "\n",
    "        self.img_size = (150, 150)\n",
    "        self.classes = {0: 'covid', 1: 'non_covid'}\n",
    "        self.groups = groups\n",
    "        self.dataset_numbers = dataset_numbers\n",
    "        self.dataset_paths = dataset_paths\n",
    "\n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Descriptor function.\n",
    "        Will print details about the dataset when called.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate description\n",
    "        msg = \"This is the {} dataset of the Lung Dataset\".format(self.groups)\n",
    "        msg += \" used for the Small Project Demo in the 50.039 Deep Learning class\"\n",
    "        msg += \" in March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(sum(self.dataset_numbers.values()))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for key, val in self.dataset_paths.items():\n",
    "            msg += \" - {}, in folder {}: {} images.\\n\".format(key, val, self.dataset_numbers[key])\n",
    "        print(msg)\n",
    "        \n",
    "    \n",
    "    def open_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'covid' or 'non-covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \n",
    "        Returns loaded image as a normalized Numpy array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Asserts checking for consistency in passed parameters\n",
    "        err_msg = \"Error - group_val variable should be set to 'train', 'test' or 'val'.\"\n",
    "        assert group_val in self.groups, err_msg\n",
    "        \n",
    "        err_msg = \"Error - class_val variable should be set to 'covid' or 'non-covid'.\"\n",
    "        assert class_val in self.classes.values(), err_msg     \n",
    "        \n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]\n",
    "        err_msg = \"Error - index_val variable should be an integer between 0 and the maximal number of images.\"\n",
    "        err_msg += \"\\n(In {}/{}, you have {} images.)\".format(group_val, class_val, max_val)\n",
    "        assert isinstance(index_val, int), err_msg\n",
    "        assert index_val >= 0 and index_val <= max_val, err_msg\n",
    "        \n",
    "        # Open file as before\n",
    "        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            im = np.asarray(Image.open(f))/255\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    \n",
    "    def show_img(self, group_val, class_val, index_val):\n",
    "        \"\"\"\n",
    "        Opens, then displays image with specified parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - group_val should take values in 'train', 'test' or 'val'.\n",
    "        - class_val variable should be set to 'covid' or 'non-covid'.\n",
    "        - index_val should be an integer with values between 0 and the maximal number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open image\n",
    "        im = self.open_img(group_val, class_val, index_val)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length special method, returns the number of images in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Length function\n",
    "        return sum(self.dataset_numbers.values())\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Getitem special method.\n",
    "        \n",
    "        Expects an integer value index, between 0 and len(self) - 1.\n",
    "        \n",
    "        Returns the image and its label as a one hot vector, both\n",
    "        in torch tensor format in dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get item special method\n",
    "        first_val = int(list(self.dataset_numbers.values())[0])\n",
    "        if index < first_val:\n",
    "            class_val = 'covid'\n",
    "            label = torch.Tensor([1, 0])\n",
    "        else:\n",
    "            class_val = 'non_covid'\n",
    "            index = index - first_val\n",
    "            label = torch.Tensor([0, 1])\n",
    "\n",
    "        im = self.open_img(self.groups, class_val, index)\n",
    "        im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MB6wqXUN5wMd"
   },
   "outputs": [],
   "source": [
    "def verify_l1_dataset(group,dataset,image_overall_index,class_val,\n",
    "                   image_specific_dataset_index=1):\n",
    "  \"\"\"\n",
    "  Helper function to verify that the classes are implemented correctly\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  group : str\n",
    "      Allowed values: train, val, test\n",
    "  dataset: object\n",
    "      Object instantiated from the class\n",
    "  image_overall_index: int\n",
    "      Overall index in the full dataset across all classes\n",
    "  class_val: str\n",
    "      Image label. Example: covid, non-covid\n",
    "  image_specific_dataset_index : int\n",
    "      image id in the specific nested directory\n",
    "  \"\"\"\n",
    "  print('Verify the special methods __len__ and __get_item__')\n",
    "  print('Number of images in {} dataset: {}'.format(group, len(dataset)))\n",
    "  print('Details for image id {} from the {} dataset'.format(\n",
    "      image_overall_index,\n",
    "      group\n",
    "  ))\n",
    "  im, class_oh = dataset[image_overall_index]\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  print('Sample image class: {}'.format(class_oh))\n",
    "\n",
    "  print('\\nVerify the open_img and show_img functions')\n",
    "  print('Open and show image {} from the {}_{} dataset'.format(\n",
    "      image_specific_dataset_index,\n",
    "      group,\n",
    "      class_val\n",
    "  ))\n",
    "  im = dataset.open_img(group, class_val, image_specific_dataset_index)\n",
    "  print('Sample image shape: {}'.format(im.shape))\n",
    "  print('Sample image: {}'.format(im))\n",
    "  dataset.show_img(group, class_val, image_specific_dataset_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIeOkWaC2n3U"
   },
   "source": [
    "### 2.3.1 Layer 1 Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McMnU4Jm6X58",
    "outputId": "9379e5db-1023-4da9-e66b-2de0054528b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the train dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 3875 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - train_covid, in folder ./dataset/train/infected/covid: 1345 images.\n",
      " - train_non_covid, in folder ./dataset/train/infected/non-covid: 2530 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_group = 'train'\n",
    "l1_ld_train = L1_Lung_Dataset(groups = train_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_1'][train_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_1'][train_group])\n",
    "l1_ld_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZt-Y09H2gcy"
   },
   "source": [
    "### 2.3.2 Layer 1 Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UP8YEmM48GAs",
    "outputId": "b86ad0d3-5039-41d3-f3b1-788cba8935cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the val dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 16 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - val_covid, in folder ./dataset/val/infected/covid: 8 images.\n",
      " - val_non_covid, in folder ./dataset/val/infected/non-covid: 8 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_group = 'val'\n",
    "l1_ld_val = L1_Lung_Dataset(groups = val_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_1'][val_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_1'][val_group])\n",
    "l1_ld_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSZCUuuS6RLL"
   },
   "source": [
    "### 2.3.3 Layer 1 Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx5IOpZN8Gws",
    "outputId": "a1d3361c-11f1-45ab-bafa-62a48b9173f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the test dataset of the Lung Dataset used for the Small Project Demo in the 50.039 Deep Learning class in March 2021. \n",
      "It contains a total of 380 images, of size 150 by 150.\n",
      "The images are stored in the following locations and each one contains the following number of images:\n",
      " - test_covid, in folder ./dataset/test/infected/covid: 138 images.\n",
      " - test_non_covid, in folder ./dataset/test/infected/non-covid: 242 images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_group = 'test'\n",
    "l1_ld_test = L1_Lung_Dataset(groups = test_group, \n",
    "                              dataset_numbers = binary_dataset_numbers['layer_1'][test_group], \n",
    "                              dataset_paths = binary_dataset_paths['layer_1'][test_group])\n",
    "l1_ld_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC14yqAz2vSI"
   },
   "source": [
    "# 3. Creating a data loader object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5YY_qNrFUTw"
   },
   "source": [
    "## 3.1 Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uiftrqf62usb"
   },
   "outputs": [],
   "source": [
    "l0_bs_train = 32\n",
    "l0_bs_test = 32\n",
    "l0_bs_val = 1\n",
    "l0_train_loader = DataLoader(l0_ld_train, batch_size = l0_bs_train, shuffle = True)\n",
    "l0_test_loader = DataLoader(l0_ld_test, batch_size = l0_bs_test, shuffle = True)\n",
    "l0_val_loader = DataLoader(l0_ld_val, batch_size = l0_bs_val, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4Fv6HyVFsfa"
   },
   "source": [
    "## 3.2 Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "wpHtBlbSFTZW"
   },
   "outputs": [],
   "source": [
    "l1_bs_train = 32\n",
    "l1_bs_test = 32\n",
    "l1_bs_val = 1\n",
    "l1_train_loader = DataLoader(l1_ld_train, batch_size = l1_bs_train, shuffle = True)\n",
    "l1_test_loader = DataLoader(l1_ld_test, batch_size = l1_bs_test, shuffle = True)\n",
    "l1_val_loader = DataLoader(l1_ld_val, batch_size = l1_bs_val, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x_-1Qe34U5w"
   },
   "source": [
    "# 4. Model\n",
    "\n",
    "https://link.springer.com/article/10.1007/s12652-021-02917-3#Sec9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVfcawPjF5sl"
   },
   "source": [
    "## 4.1 Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-yJ7JTk04XIu"
   },
   "outputs": [],
   "source": [
    "class L0_Net(nn.Module):\n",
    "    def __init__(self, num_layers=1):\n",
    "        super(L0_Net, self).__init__()\n",
    "        # Conv2D: 1 input channel, 4 output channels, 3 by 3 kernel, stride of 1.\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(8, 32, 3, 1)\n",
    "        self.avgpool = nn.AvgPool2d(3)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "        self.fc1 = nn.Linear(16928, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJKx7kXTQYQN",
    "outputId": "3b65b8c6-a923-4f89-f83e-8962961cd577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n"
     ]
    }
   ],
   "source": [
    "# Activate gpu\n",
    "if torch.cuda.is_available():  \n",
    "    print('using GPU')\n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "l0_model = L0_Net().to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoBbl4-OO417",
    "outputId": "f3d2aa22-250a-4198-deea-5bed17428e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 148, 148]             160\n",
      "         Dropout2d-2         [-1, 16, 148, 148]               0\n",
      "              ReLU-3         [-1, 16, 148, 148]               0\n",
      "            Conv2d-4          [-1, 8, 146, 146]           1,160\n",
      "              ReLU-5          [-1, 8, 146, 146]               0\n",
      "         MaxPool2d-6            [-1, 8, 73, 73]               0\n",
      "         Dropout2d-7            [-1, 8, 73, 73]               0\n",
      "            Conv2d-8           [-1, 32, 71, 71]           2,336\n",
      "              ReLU-9           [-1, 32, 71, 71]               0\n",
      "        AvgPool2d-10           [-1, 32, 23, 23]               0\n",
      "        Dropout2d-11           [-1, 32, 23, 23]               0\n",
      "             ReLU-12           [-1, 32, 23, 23]               0\n",
      "           Linear-13                    [-1, 2]          33,858\n",
      "================================================================\n",
      "Total params: 37,514\n",
      "Trainable params: 37,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 14.12\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 14.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(l0_model, (1, 150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUtueamzGHp9"
   },
   "source": [
    "## 4.2 Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "El3FLR03GJ5m"
   },
   "outputs": [],
   "source": [
    "class L1_Net(nn.Module):\n",
    "    def __init__(self, num_layers=1):\n",
    "        super(L1_Net, self).__init__()\n",
    "        # Conv2D: 1 input channel, 4 output channels, 3 by 3 kernel, stride of 1.\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(8, 32, 3, 1)\n",
    "        self.avgpool = nn.AvgPool2d(3)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2)\n",
    "        self.fc1 = nn.Linear(16928, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        output = F.log_softmax(x, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3uSnZgeGKO-",
    "outputId": "af1fa8f1-4e48-4b26-a9a3-30c0892902d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n"
     ]
    }
   ],
   "source": [
    "# Activate gpu\n",
    "if torch.cuda.is_available():  \n",
    "    print('using GPU')\n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "l1_model = L1_Net().to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tRV7PJIGPTH",
    "outputId": "02c17861-2d3b-4165-bcac-46bb06c4cb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 148, 148]             160\n",
      "         Dropout2d-2         [-1, 16, 148, 148]               0\n",
      "              ReLU-3         [-1, 16, 148, 148]               0\n",
      "            Conv2d-4          [-1, 8, 146, 146]           1,160\n",
      "              ReLU-5          [-1, 8, 146, 146]               0\n",
      "         MaxPool2d-6            [-1, 8, 73, 73]               0\n",
      "         Dropout2d-7            [-1, 8, 73, 73]               0\n",
      "            Conv2d-8           [-1, 32, 71, 71]           2,336\n",
      "              ReLU-9           [-1, 32, 71, 71]               0\n",
      "        AvgPool2d-10           [-1, 32, 23, 23]               0\n",
      "        Dropout2d-11           [-1, 32, 23, 23]               0\n",
      "             ReLU-12           [-1, 32, 23, 23]               0\n",
      "           Linear-13                    [-1, 2]          33,858\n",
      "================================================================\n",
      "Total params: 37,514\n",
      "Trainable params: 37,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 14.12\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 14.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(l1_model, (1, 150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1E4MDvTLdnP"
   },
   "source": [
    "# 5. Training the model\n",
    "\n",
    "Reference material: [Towards data science: PyTorch [Tabular] — Multiclass Classification](https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "98hO2OLpLdRK"
   },
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.1 GridSearch for Layer 0\n",
    "\n",
    "## Hyperparameters \n",
    "'epochs': [5, 10]\n",
    "'lr': [0.0001, 0.00001]\n",
    "'scheduler_gamma': [0.1, 0.001]\n",
    "'l1_lambda': [0.5, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_L0(epochs, lr, scheduler_gamma, l1_lambda, log_path='../layer_0_gridsearch.log'):\n",
    "    \n",
    "    # Activate gpu\n",
    "    if torch.cuda.is_available():  \n",
    "        print('using GPU')\n",
    "        device = \"cuda:0\" \n",
    "    else:  \n",
    "        device = \"cpu\"\n",
    "        \n",
    "    # Load a fresh network\n",
    "    l0_model = L0_Net().to(torch.device(device))\n",
    "    \n",
    "    # setup\n",
    "    weight_decay = 0.00001\n",
    "    l0_class_weights = torch.tensor([2.83, 1.0]).to(torch.device(device))\n",
    "    criterion = nn.CrossEntropyLoss(l0_class_weights)\n",
    "    optimizer = optim.AdamW(l0_model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=scheduler_gamma)\n",
    "    \n",
    "    start = time.time()\n",
    "    start_model_time = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    \n",
    "    L1_reg = torch.tensor(0., requires_grad=True)\n",
    "    for name, param in l0_model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            L1_reg = L1_reg + torch.norm(param, 1)\n",
    "    \n",
    "    # Save log for hyperparameters\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(\"{} : Training L0 model - epochs {} - lr {} - scheduler_gamma {} - l1_lambda - {} \\n\".format(start_model_time, epochs, lr, scheduler_gamma, l1_lambda))\n",
    "    \n",
    "    l0_accuracy_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "    l0_loss_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_acc = 0\n",
    "\n",
    "        l0_model.train()\n",
    "        for batch_idx, (X_train_batch, y_train_batch) in enumerate(l0_train_loader):\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = l0_model.forward(X_train_batch)\n",
    "            train_loss  = criterion(output, torch.max(y_train_batch, 1)[1])\n",
    "            train_acc = multi_acc(output, torch.max(y_train_batch, 1)[1])\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step(e + batch_idx / len(l0_train_loader))\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            train_epoch_acc += train_acc.item()\n",
    "            \n",
    "        # update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # testing\n",
    "        with torch.no_grad():\n",
    "            test_epoch_loss = 0\n",
    "            test_epoch_acc = 0\n",
    "            l0_model.eval()\n",
    "            for X_test_batch, y_test_batch in l0_test_loader:\n",
    "                X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "\n",
    "                y_test_pred = l0_model.forward(X_test_batch)\n",
    "\n",
    "                test_loss = criterion(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "                test_acc = multi_acc(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "\n",
    "                test_epoch_loss += test_loss.item()\n",
    "                test_epoch_acc += test_acc.item()\n",
    "\n",
    "\n",
    "        # averaged\n",
    "        train_epoch_loss = train_epoch_loss/len(l0_train_loader)\n",
    "        train_epoch_acc = train_epoch_acc/len(l0_train_loader)\n",
    "        test_epoch_loss = test_epoch_loss/len(l0_test_loader)\n",
    "        test_epoch_acc = test_epoch_acc/len(l0_test_loader)\n",
    "\n",
    "        # The step number corresponds to the number of batches seen\n",
    "        now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        print(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now),\n",
    "          \"Training Loss: {:.4f} - \".format(train_epoch_loss),\n",
    "          \"Training Accuracy: {:.4f}\".format(train_epoch_acc),\n",
    "          \"Test Loss: {:.4f} - \".format(test_epoch_loss),\n",
    "          \"Test Accuracy: {:.4f}\".format(test_epoch_acc))\n",
    "        l0_model.train()\n",
    "        \n",
    "        # save the logs\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now))\n",
    "            f.write(\"Training Loss: {:.4f} - \".format(train_epoch_loss))\n",
    "            f.write(\"Training Accuracy: {:.4f} - \".format(train_epoch_acc))\n",
    "            f.write(\"Test Loss: {:.4f} - \".format(test_epoch_loss))\n",
    "            f.write(\"Test Accuracy: {:.4f}\\n\\n\".format(test_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:01:37 -  Training Loss: 0.6498 -  Training Accuracy: 0.6595 Test Loss: 0.4764 -  Test Accuracy: 0.7833\n",
      "Epoch: 2/5 - 21/03/2021 00:01:45 -  Training Loss: 0.3294 -  Training Accuracy: 0.8704 Test Loss: 0.3467 -  Test Accuracy: 0.8354\n",
      "Epoch: 3/5 - 21/03/2021 00:01:54 -  Training Loss: 0.2265 -  Training Accuracy: 0.9156 Test Loss: 0.7920 -  Test Accuracy: 0.7745\n",
      "Epoch: 4/5 - 21/03/2021 00:02:03 -  Training Loss: 0.2008 -  Training Accuracy: 0.9291 Test Loss: 0.7452 -  Test Accuracy: 0.8031\n",
      "Epoch: 5/5 - 21/03/2021 00:02:11 -  Training Loss: 0.1885 -  Training Accuracy: 0.9298 Test Loss: 0.7357 -  Test Accuracy: 0.8010\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:02:20 -  Training Loss: 0.5777 -  Training Accuracy: 0.7485 Test Loss: 0.5365 -  Test Accuracy: 0.7896\n",
      "Epoch: 2/10 - 21/03/2021 00:02:29 -  Training Loss: 0.3142 -  Training Accuracy: 0.8769 Test Loss: 0.5446 -  Test Accuracy: 0.8115\n",
      "Epoch: 3/10 - 21/03/2021 00:02:38 -  Training Loss: 0.2304 -  Training Accuracy: 0.9149 Test Loss: 0.4523 -  Test Accuracy: 0.8422\n",
      "Epoch: 4/10 - 21/03/2021 00:02:49 -  Training Loss: 0.2083 -  Training Accuracy: 0.9212 Test Loss: 1.0213 -  Test Accuracy: 0.7641\n",
      "Epoch: 5/10 - 21/03/2021 00:02:59 -  Training Loss: 0.2058 -  Training Accuracy: 0.9247 Test Loss: 0.4704 -  Test Accuracy: 0.8250\n",
      "Epoch: 6/10 - 21/03/2021 00:03:09 -  Training Loss: 0.1758 -  Training Accuracy: 0.9337 Test Loss: 0.9582 -  Test Accuracy: 0.7677\n",
      "Epoch: 7/10 - 21/03/2021 00:03:18 -  Training Loss: 0.1628 -  Training Accuracy: 0.9369 Test Loss: 0.8206 -  Test Accuracy: 0.7786\n",
      "Epoch: 8/10 - 21/03/2021 00:03:27 -  Training Loss: 0.1639 -  Training Accuracy: 0.9404 Test Loss: 0.7630 -  Test Accuracy: 0.7995\n",
      "Epoch: 9/10 - 21/03/2021 00:03:36 -  Training Loss: 0.1617 -  Training Accuracy: 0.9396 Test Loss: 0.8536 -  Test Accuracy: 0.7854\n",
      "Epoch: 10/10 - 21/03/2021 00:03:46 -  Training Loss: 0.1576 -  Training Accuracy: 0.9431 Test Loss: 0.8718 -  Test Accuracy: 0.7901\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:03:55 -  Training Loss: 0.6918 -  Training Accuracy: 0.6827 Test Loss: 0.6941 -  Test Accuracy: 0.6276\n",
      "Epoch: 2/5 - 21/03/2021 00:04:04 -  Training Loss: 0.6861 -  Training Accuracy: 0.7527 Test Loss: 0.6878 -  Test Accuracy: 0.7484\n",
      "Epoch: 3/5 - 21/03/2021 00:04:13 -  Training Loss: 0.6718 -  Training Accuracy: 0.7826 Test Loss: 0.6771 -  Test Accuracy: 0.7661\n",
      "Epoch: 4/5 - 21/03/2021 00:04:22 -  Training Loss: 0.6417 -  Training Accuracy: 0.8447 Test Loss: 0.6489 -  Test Accuracy: 0.8229\n",
      "Epoch: 5/5 - 21/03/2021 00:04:31 -  Training Loss: 0.5899 -  Training Accuracy: 0.8591 Test Loss: 0.5860 -  Test Accuracy: 0.8375\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:04:40 -  Training Loss: 0.6901 -  Training Accuracy: 0.6919 Test Loss: 0.6848 -  Test Accuracy: 0.6062\n",
      "Epoch: 2/10 - 21/03/2021 00:04:48 -  Training Loss: 0.6765 -  Training Accuracy: 0.6660 Test Loss: 0.6827 -  Test Accuracy: 0.6984\n",
      "Epoch: 3/10 - 21/03/2021 00:04:57 -  Training Loss: 0.6468 -  Training Accuracy: 0.8407 Test Loss: 0.6506 -  Test Accuracy: 0.8016\n",
      "Epoch: 4/10 - 21/03/2021 00:05:06 -  Training Loss: 0.5935 -  Training Accuracy: 0.8599 Test Loss: 0.5977 -  Test Accuracy: 0.8297\n",
      "Epoch: 5/10 - 21/03/2021 00:05:15 -  Training Loss: 0.5193 -  Training Accuracy: 0.8669 Test Loss: 0.5537 -  Test Accuracy: 0.8161\n",
      "Epoch: 6/10 - 21/03/2021 00:05:25 -  Training Loss: 0.4817 -  Training Accuracy: 0.8738 Test Loss: 0.5441 -  Test Accuracy: 0.8094\n",
      "Epoch: 7/10 - 21/03/2021 00:05:34 -  Training Loss: 0.4768 -  Training Accuracy: 0.8708 Test Loss: 0.5346 -  Test Accuracy: 0.8161\n",
      "Epoch: 8/10 - 21/03/2021 00:05:43 -  Training Loss: 0.4690 -  Training Accuracy: 0.8723 Test Loss: 0.5307 -  Test Accuracy: 0.8229\n",
      "Epoch: 9/10 - 21/03/2021 00:05:52 -  Training Loss: 0.4645 -  Training Accuracy: 0.8760 Test Loss: 0.5246 -  Test Accuracy: 0.8177\n",
      "Epoch: 10/10 - 21/03/2021 00:06:02 -  Training Loss: 0.4609 -  Training Accuracy: 0.8750 Test Loss: 0.5196 -  Test Accuracy: 0.8094\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:06:11 -  Training Loss: 0.6153 -  Training Accuracy: 0.6879 Test Loss: 0.4489 -  Test Accuracy: 0.7760\n",
      "Epoch: 2/5 - 21/03/2021 00:06:20 -  Training Loss: 0.3445 -  Training Accuracy: 0.8706 Test Loss: 0.3815 -  Test Accuracy: 0.8417\n",
      "Epoch: 3/5 - 21/03/2021 00:06:28 -  Training Loss: 0.2502 -  Training Accuracy: 0.9043 Test Loss: 0.6196 -  Test Accuracy: 0.8016\n",
      "Epoch: 4/5 - 21/03/2021 00:06:37 -  Training Loss: 0.2373 -  Training Accuracy: 0.9080 Test Loss: 0.6877 -  Test Accuracy: 0.7943\n",
      "Epoch: 5/5 - 21/03/2021 00:06:46 -  Training Loss: 0.1907 -  Training Accuracy: 0.9308 Test Loss: 0.9046 -  Test Accuracy: 0.7807\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:06:55 -  Training Loss: 0.6404 -  Training Accuracy: 0.6957 Test Loss: 0.5368 -  Test Accuracy: 0.8167\n",
      "Epoch: 2/10 - 21/03/2021 00:07:05 -  Training Loss: 0.3264 -  Training Accuracy: 0.8769 Test Loss: 0.6587 -  Test Accuracy: 0.7740\n",
      "Epoch: 3/10 - 21/03/2021 00:07:14 -  Training Loss: 0.2274 -  Training Accuracy: 0.9116 Test Loss: 0.9030 -  Test Accuracy: 0.7734\n",
      "Epoch: 4/10 - 21/03/2021 00:07:23 -  Training Loss: 0.1949 -  Training Accuracy: 0.9214 Test Loss: 1.3029 -  Test Accuracy: 0.7406\n",
      "Epoch: 5/10 - 21/03/2021 00:07:32 -  Training Loss: 0.1825 -  Training Accuracy: 0.9335 Test Loss: 0.8011 -  Test Accuracy: 0.7932\n",
      "Epoch: 6/10 - 21/03/2021 00:07:42 -  Training Loss: 0.1646 -  Training Accuracy: 0.9367 Test Loss: 0.8770 -  Test Accuracy: 0.7797\n",
      "Epoch: 7/10 - 21/03/2021 00:07:51 -  Training Loss: 0.1609 -  Training Accuracy: 0.9346 Test Loss: 0.8071 -  Test Accuracy: 0.7849\n",
      "Epoch: 8/10 - 21/03/2021 00:08:00 -  Training Loss: 0.1623 -  Training Accuracy: 0.9363 Test Loss: 0.8069 -  Test Accuracy: 0.7917\n",
      "Epoch: 9/10 - 21/03/2021 00:08:09 -  Training Loss: 0.1646 -  Training Accuracy: 0.9385 Test Loss: 0.8287 -  Test Accuracy: 0.7917\n",
      "Epoch: 10/10 - 21/03/2021 00:08:18 -  Training Loss: 0.1640 -  Training Accuracy: 0.9352 Test Loss: 0.8439 -  Test Accuracy: 0.7849\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:08:27 -  Training Loss: 0.6929 -  Training Accuracy: 0.6714 Test Loss: 0.6876 -  Test Accuracy: 0.3792\n",
      "Epoch: 2/5 - 21/03/2021 00:08:36 -  Training Loss: 0.6903 -  Training Accuracy: 0.6106 Test Loss: 0.6927 -  Test Accuracy: 0.6443\n",
      "Epoch: 3/5 - 21/03/2021 00:08:45 -  Training Loss: 0.6876 -  Training Accuracy: 0.6633 Test Loss: 0.6956 -  Test Accuracy: 0.6208\n",
      "Epoch: 4/5 - 21/03/2021 00:08:54 -  Training Loss: 0.6829 -  Training Accuracy: 0.6656 Test Loss: 0.7147 -  Test Accuracy: 0.6208\n",
      "Epoch: 5/5 - 21/03/2021 00:09:03 -  Training Loss: 0.6756 -  Training Accuracy: 0.7241 Test Loss: 0.6758 -  Test Accuracy: 0.7984\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:09:11 -  Training Loss: 0.6924 -  Training Accuracy: 0.6116 Test Loss: 0.6963 -  Test Accuracy: 0.6344\n",
      "Epoch: 2/10 - 21/03/2021 00:09:20 -  Training Loss: 0.6901 -  Training Accuracy: 0.6643 Test Loss: 0.7001 -  Test Accuracy: 0.6276\n",
      "Epoch: 3/10 - 21/03/2021 00:09:29 -  Training Loss: 0.6842 -  Training Accuracy: 0.7552 Test Loss: 0.6895 -  Test Accuracy: 0.6552\n",
      "Epoch: 4/10 - 21/03/2021 00:09:39 -  Training Loss: 0.6695 -  Training Accuracy: 0.7866 Test Loss: 0.6552 -  Test Accuracy: 0.7719\n",
      "Epoch: 5/10 - 21/03/2021 00:09:48 -  Training Loss: 0.6297 -  Training Accuracy: 0.8303 Test Loss: 0.6144 -  Test Accuracy: 0.7937\n",
      "Epoch: 6/10 - 21/03/2021 00:09:57 -  Training Loss: 0.6005 -  Training Accuracy: 0.8378 Test Loss: 0.6120 -  Test Accuracy: 0.8021\n",
      "Epoch: 7/10 - 21/03/2021 00:10:07 -  Training Loss: 0.5999 -  Training Accuracy: 0.8322 Test Loss: 0.6098 -  Test Accuracy: 0.8089\n",
      "Epoch: 8/10 - 21/03/2021 00:10:16 -  Training Loss: 0.6005 -  Training Accuracy: 0.8315 Test Loss: 0.6102 -  Test Accuracy: 0.8089\n",
      "Epoch: 9/10 - 21/03/2021 00:10:24 -  Training Loss: 0.6011 -  Training Accuracy: 0.8361 Test Loss: 0.6111 -  Test Accuracy: 0.8036\n",
      "Epoch: 10/10 - 21/03/2021 00:10:33 -  Training Loss: 0.6014 -  Training Accuracy: 0.8315 Test Loss: 0.6101 -  Test Accuracy: 0.8089\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:10:42 -  Training Loss: 0.5530 -  Training Accuracy: 0.7707 Test Loss: 0.3997 -  Test Accuracy: 0.8214\n",
      "Epoch: 2/5 - 21/03/2021 00:10:51 -  Training Loss: 0.2752 -  Training Accuracy: 0.8988 Test Loss: 0.4910 -  Test Accuracy: 0.8182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5 - 21/03/2021 00:11:00 -  Training Loss: 0.2093 -  Training Accuracy: 0.9197 Test Loss: 0.6034 -  Test Accuracy: 0.8042\n",
      "Epoch: 4/5 - 21/03/2021 00:11:10 -  Training Loss: 0.1833 -  Training Accuracy: 0.9317 Test Loss: 0.7927 -  Test Accuracy: 0.7854\n",
      "Epoch: 5/5 - 21/03/2021 00:11:19 -  Training Loss: 0.1786 -  Training Accuracy: 0.9344 Test Loss: 1.0744 -  Test Accuracy: 0.7641\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:11:29 -  Training Loss: 0.6811 -  Training Accuracy: 0.6081 Test Loss: 0.6301 -  Test Accuracy: 0.7651\n",
      "Epoch: 2/10 - 21/03/2021 00:11:38 -  Training Loss: 0.4391 -  Training Accuracy: 0.8322 Test Loss: 0.3757 -  Test Accuracy: 0.8286\n",
      "Epoch: 3/10 - 21/03/2021 00:11:47 -  Training Loss: 0.2621 -  Training Accuracy: 0.8999 Test Loss: 0.3713 -  Test Accuracy: 0.8385\n",
      "Epoch: 4/10 - 21/03/2021 00:11:56 -  Training Loss: 0.2147 -  Training Accuracy: 0.9197 Test Loss: 0.6521 -  Test Accuracy: 0.8063\n",
      "Epoch: 5/10 - 21/03/2021 00:12:05 -  Training Loss: 0.2076 -  Training Accuracy: 0.9231 Test Loss: 1.2274 -  Test Accuracy: 0.7427\n",
      "Epoch: 6/10 - 21/03/2021 00:12:14 -  Training Loss: 0.1784 -  Training Accuracy: 0.9377 Test Loss: 0.7903 -  Test Accuracy: 0.7750\n",
      "Epoch: 7/10 - 21/03/2021 00:12:23 -  Training Loss: 0.1703 -  Training Accuracy: 0.9356 Test Loss: 0.8036 -  Test Accuracy: 0.7833\n",
      "Epoch: 8/10 - 21/03/2021 00:12:32 -  Training Loss: 0.1742 -  Training Accuracy: 0.9385 Test Loss: 0.7296 -  Test Accuracy: 0.8016\n",
      "Epoch: 9/10 - 21/03/2021 00:12:41 -  Training Loss: 0.1735 -  Training Accuracy: 0.9362 Test Loss: 0.8600 -  Test Accuracy: 0.7771\n",
      "Epoch: 10/10 - 21/03/2021 00:12:51 -  Training Loss: 0.1701 -  Training Accuracy: 0.9387 Test Loss: 0.8118 -  Test Accuracy: 0.7818\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:13:00 -  Training Loss: 0.6921 -  Training Accuracy: 0.5554 Test Loss: 0.7026 -  Test Accuracy: 0.6276\n",
      "Epoch: 2/5 - 21/03/2021 00:13:09 -  Training Loss: 0.6852 -  Training Accuracy: 0.7533 Test Loss: 0.6931 -  Test Accuracy: 0.6276\n",
      "Epoch: 3/5 - 21/03/2021 00:13:18 -  Training Loss: 0.6702 -  Training Accuracy: 0.7908 Test Loss: 0.6699 -  Test Accuracy: 0.8109\n",
      "Epoch: 4/5 - 21/03/2021 00:13:27 -  Training Loss: 0.6443 -  Training Accuracy: 0.8424 Test Loss: 0.6378 -  Test Accuracy: 0.8406\n",
      "Epoch: 5/5 - 21/03/2021 00:13:37 -  Training Loss: 0.5993 -  Training Accuracy: 0.8526 Test Loss: 0.6239 -  Test Accuracy: 0.8000\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:13:46 -  Training Loss: 0.6922 -  Training Accuracy: 0.6821 Test Loss: 0.6970 -  Test Accuracy: 0.6276\n",
      "Epoch: 2/10 - 21/03/2021 00:13:56 -  Training Loss: 0.6900 -  Training Accuracy: 0.7051 Test Loss: 0.6984 -  Test Accuracy: 0.6276\n",
      "Epoch: 3/10 - 21/03/2021 00:14:05 -  Training Loss: 0.6854 -  Training Accuracy: 0.7304 Test Loss: 0.6930 -  Test Accuracy: 0.6208\n",
      "Epoch: 4/10 - 21/03/2021 00:14:15 -  Training Loss: 0.6758 -  Training Accuracy: 0.7916 Test Loss: 0.6826 -  Test Accuracy: 0.7323\n",
      "Epoch: 5/10 - 21/03/2021 00:14:25 -  Training Loss: 0.6622 -  Training Accuracy: 0.8142 Test Loss: 0.6660 -  Test Accuracy: 0.8125\n",
      "Epoch: 6/10 - 21/03/2021 00:14:35 -  Training Loss: 0.6529 -  Training Accuracy: 0.8278 Test Loss: 0.6642 -  Test Accuracy: 0.8026\n",
      "Epoch: 7/10 - 21/03/2021 00:14:44 -  Training Loss: 0.6502 -  Training Accuracy: 0.8372 Test Loss: 0.6617 -  Test Accuracy: 0.8141\n",
      "Epoch: 8/10 - 21/03/2021 00:14:54 -  Training Loss: 0.6492 -  Training Accuracy: 0.8401 Test Loss: 0.6620 -  Test Accuracy: 0.7906\n",
      "Epoch: 9/10 - 21/03/2021 00:15:04 -  Training Loss: 0.6469 -  Training Accuracy: 0.8388 Test Loss: 0.6615 -  Test Accuracy: 0.7958\n",
      "Epoch: 10/10 - 21/03/2021 00:15:13 -  Training Loss: 0.6458 -  Training Accuracy: 0.8438 Test Loss: 0.6607 -  Test Accuracy: 0.7906\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:15:23 -  Training Loss: 0.5923 -  Training Accuracy: 0.6979 Test Loss: 0.5089 -  Test Accuracy: 0.8156\n",
      "Epoch: 2/5 - 21/03/2021 00:15:32 -  Training Loss: 0.2814 -  Training Accuracy: 0.9011 Test Loss: 0.5091 -  Test Accuracy: 0.8276\n",
      "Epoch: 3/5 - 21/03/2021 00:15:41 -  Training Loss: 0.2141 -  Training Accuracy: 0.9191 Test Loss: 0.9113 -  Test Accuracy: 0.7781\n",
      "Epoch: 4/5 - 21/03/2021 00:15:51 -  Training Loss: 0.1785 -  Training Accuracy: 0.9333 Test Loss: 0.7227 -  Test Accuracy: 0.7891\n",
      "Epoch: 5/5 - 21/03/2021 00:16:00 -  Training Loss: 0.1729 -  Training Accuracy: 0.9356 Test Loss: 0.8666 -  Test Accuracy: 0.7875\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:16:10 -  Training Loss: 0.6344 -  Training Accuracy: 0.7118 Test Loss: 0.5058 -  Test Accuracy: 0.8156\n",
      "Epoch: 2/10 - 21/03/2021 00:16:19 -  Training Loss: 0.3198 -  Training Accuracy: 0.8880 Test Loss: 0.5207 -  Test Accuracy: 0.8214\n",
      "Epoch: 3/10 - 21/03/2021 00:16:28 -  Training Loss: 0.2215 -  Training Accuracy: 0.9170 Test Loss: 0.7296 -  Test Accuracy: 0.7854\n",
      "Epoch: 4/10 - 21/03/2021 00:16:38 -  Training Loss: 0.1955 -  Training Accuracy: 0.9291 Test Loss: 0.9040 -  Test Accuracy: 0.7745\n",
      "Epoch: 5/10 - 21/03/2021 00:16:47 -  Training Loss: 0.1812 -  Training Accuracy: 0.9329 Test Loss: 0.8022 -  Test Accuracy: 0.7969\n",
      "Epoch: 6/10 - 21/03/2021 00:16:57 -  Training Loss: 0.1689 -  Training Accuracy: 0.9287 Test Loss: 0.8684 -  Test Accuracy: 0.7766\n",
      "Epoch: 7/10 - 21/03/2021 00:17:07 -  Training Loss: 0.1706 -  Training Accuracy: 0.9281 Test Loss: 0.8385 -  Test Accuracy: 0.7932\n",
      "Epoch: 8/10 - 21/03/2021 00:17:17 -  Training Loss: 0.1654 -  Training Accuracy: 0.9314 Test Loss: 0.8477 -  Test Accuracy: 0.7865\n",
      "Epoch: 9/10 - 21/03/2021 00:17:26 -  Training Loss: 0.1711 -  Training Accuracy: 0.9308 Test Loss: 0.8797 -  Test Accuracy: 0.7865\n",
      "Epoch: 10/10 - 21/03/2021 00:17:36 -  Training Loss: 0.1701 -  Training Accuracy: 0.9270 Test Loss: 0.9144 -  Test Accuracy: 0.7766\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:17:46 -  Training Loss: 0.6931 -  Training Accuracy: 0.6355 Test Loss: 0.6948 -  Test Accuracy: 0.6344\n",
      "Epoch: 2/5 - 21/03/2021 00:17:56 -  Training Loss: 0.6901 -  Training Accuracy: 0.7335 Test Loss: 0.6896 -  Test Accuracy: 0.7719\n",
      "Epoch: 3/5 - 21/03/2021 00:18:05 -  Training Loss: 0.6869 -  Training Accuracy: 0.6804 Test Loss: 0.6924 -  Test Accuracy: 0.6281\n",
      "Epoch: 4/5 - 21/03/2021 00:18:15 -  Training Loss: 0.6809 -  Training Accuracy: 0.7699 Test Loss: 0.6840 -  Test Accuracy: 0.7693\n",
      "Epoch: 5/5 - 21/03/2021 00:18:24 -  Training Loss: 0.6696 -  Training Accuracy: 0.7600 Test Loss: 0.6677 -  Test Accuracy: 0.7865\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:18:33 -  Training Loss: 0.6929 -  Training Accuracy: 0.5767 Test Loss: 0.6999 -  Test Accuracy: 0.6005\n",
      "Epoch: 2/10 - 21/03/2021 00:18:43 -  Training Loss: 0.6891 -  Training Accuracy: 0.7186 Test Loss: 0.6942 -  Test Accuracy: 0.6208\n",
      "Epoch: 3/10 - 21/03/2021 00:18:52 -  Training Loss: 0.6813 -  Training Accuracy: 0.7469 Test Loss: 0.6852 -  Test Accuracy: 0.7391\n",
      "Epoch: 4/10 - 21/03/2021 00:19:01 -  Training Loss: 0.6640 -  Training Accuracy: 0.8012 Test Loss: 0.6622 -  Test Accuracy: 0.8182\n",
      "Epoch: 5/10 - 21/03/2021 00:19:10 -  Training Loss: 0.6356 -  Training Accuracy: 0.8025 Test Loss: 0.6357 -  Test Accuracy: 0.8203\n",
      "Epoch: 6/10 - 21/03/2021 00:19:20 -  Training Loss: 0.6142 -  Training Accuracy: 0.8491 Test Loss: 0.6356 -  Test Accuracy: 0.8135\n",
      "Epoch: 7/10 - 21/03/2021 00:19:29 -  Training Loss: 0.6146 -  Training Accuracy: 0.8466 Test Loss: 0.6353 -  Test Accuracy: 0.8135\n",
      "Epoch: 8/10 - 21/03/2021 00:19:38 -  Training Loss: 0.6156 -  Training Accuracy: 0.8430 Test Loss: 0.6338 -  Test Accuracy: 0.8203\n",
      "Epoch: 9/10 - 21/03/2021 00:19:48 -  Training Loss: 0.6144 -  Training Accuracy: 0.8418 Test Loss: 0.6364 -  Test Accuracy: 0.8120\n",
      "Epoch: 10/10 - 21/03/2021 00:19:57 -  Training Loss: 0.6148 -  Training Accuracy: 0.8422 Test Loss: 0.6362 -  Test Accuracy: 0.8052\n"
     ]
    }
   ],
   "source": [
    "# epochs\n",
    "train_model_L0(epochs= 5, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "\n",
    "# learning rate\n",
    "train_model_L0(epochs= 5, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "train_model_L0(epochs= 10, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "\n",
    "# scheduler gamma\n",
    "train_model_L0(epochs= 5, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "train_model_L0(epochs= 5, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "train_model_L0(epochs= 10, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "\n",
    "# l1 lambda\n",
    "train_model_L0(epochs= 5, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L0(epochs= 5, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L0(epochs= 10, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L0(epochs= 5, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.01)\n",
    "train_model_L0(epochs= 10, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.01)\n",
    "train_model_L0(epochs= 5, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.01)\n",
    "train_model_L0(epochs= 10, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRYDiwdsL4vB"
   },
   "source": [
    "## 5.2 Layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.1 GridSearch for Layer 1\n",
    "hyperparameters\n",
    "'epochs': [5, 10] 'lr': [0.0001, 0.00001] 'scheduler_gamma': [0.1, 0.001] 'l1_lambda': [0.5, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_L1(epochs, lr, scheduler_gamma, l1_lambda, log_path='../layer_1_gridsearch.log'):\n",
    "    \n",
    "    # Activate gpu\n",
    "    if torch.cuda.is_available():  \n",
    "        print('using GPU')\n",
    "        device = \"cuda:0\" \n",
    "    else:  \n",
    "        device = \"cpu\"\n",
    "        \n",
    "    # Load a fresh network\n",
    "    l1_model = L1_Net().to(torch.device(device))\n",
    "    \n",
    "    # setup\n",
    "    weight_decay = 0.00001\n",
    "    l1_class_weights = torch.tensor([2.83, 1.0]).to(torch.device(device))\n",
    "    criterion = nn.CrossEntropyLoss(l0_class_weights)\n",
    "    optimizer = optim.AdamW(l1_model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    \n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=scheduler_gamma)\n",
    "    \n",
    "    start = time.time()\n",
    "    start_model_time = datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "    \n",
    "    L1_reg = torch.tensor(0., requires_grad=True)\n",
    "    for name, param in l1_model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            L1_reg = L1_reg + torch.norm(param, 1)\n",
    "    \n",
    "    # Save log for hyperparameters\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(\"{} : Training L1 model - epochs {} - lr {} - scheduler_gamma {} - l1_lambda - {} \\n\".format(start_model_time, epochs, lr, scheduler_gamma, l1_lambda))\n",
    "    \n",
    "    l1_accuracy_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "    l1_loss_stats_epoch = {\n",
    "        'train': [],\n",
    "        'test': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_acc = 0\n",
    "\n",
    "        l1_model.train()\n",
    "        for batch_idx, (X_train_batch, y_train_batch) in enumerate(l1_train_loader):\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = l1_model.forward(X_train_batch)\n",
    "            train_loss  = criterion(output, torch.max(y_train_batch, 1)[1])\n",
    "            train_acc = multi_acc(output, torch.max(y_train_batch, 1)[1])\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            train_epoch_acc += train_acc.item()\n",
    "            \n",
    "        # update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # testing\n",
    "        with torch.no_grad():\n",
    "            test_epoch_loss = 0\n",
    "            test_epoch_acc = 0\n",
    "            l1_model.eval()\n",
    "            for X_test_batch, y_test_batch in l1_test_loader:\n",
    "                X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "\n",
    "                y_test_pred = l1_model.forward(X_test_batch)\n",
    "\n",
    "                test_loss = criterion(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "                test_acc = multi_acc(y_test_pred, torch.max(y_test_batch, 1)[1])\n",
    "\n",
    "                test_epoch_loss += test_loss.item()\n",
    "                test_epoch_acc += test_acc.item()\n",
    "\n",
    "\n",
    "        # averaged\n",
    "        train_epoch_loss = train_epoch_loss/len(l1_train_loader)\n",
    "        train_epoch_acc = train_epoch_acc/len(l1_train_loader)\n",
    "        test_epoch_loss = test_epoch_loss/len(l1_test_loader)\n",
    "        test_epoch_acc = test_epoch_acc/len(l1_test_loader)\n",
    "\n",
    "        # The step number corresponds to the number of batches seen\n",
    "        now = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        print(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now),\n",
    "          \"Training Loss: {:.4f} - \".format(train_epoch_loss),\n",
    "          \"Training Accuracy: {:.4f}\".format(train_epoch_acc),\n",
    "          \"Test Loss: {:.4f} - \".format(test_epoch_loss),\n",
    "          \"Test Accuracy: {:.4f}\".format(test_epoch_acc))\n",
    "        l1_model.train()\n",
    "\n",
    "        # Epoch metrics\n",
    "        l1_loss_stats_epoch['train'].append(train_epoch_loss)\n",
    "        l1_loss_stats_epoch['test'].append(test_epoch_loss)\n",
    "        l1_loss_stats_epoch['epoch'].append(e+1)\n",
    "        l1_accuracy_stats_epoch['train'].append(train_epoch_acc)\n",
    "        l1_accuracy_stats_epoch['test'].append(test_epoch_acc)\n",
    "        l1_accuracy_stats_epoch['epoch'].append(e+1)\n",
    "\n",
    "        # save the logs\n",
    "        with open(log_path, \"a\") as f:\n",
    "            f.write(\"Epoch: {}/{} - {} - \".format(e+1, epochs, now))\n",
    "            f.write(\"Training Loss: {:.4f} - \".format(train_epoch_loss))\n",
    "            f.write(\"Training Accuracy: {:.4f} - \".format(train_epoch_acc))\n",
    "            f.write(\"Test Loss: {:.4f} - \".format(test_epoch_loss))\n",
    "            f.write(\"Test Accuracy: {:.4f}\\\\n\".format(test_epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:39:40 -  Training Loss: 0.6748 -  Training Accuracy: 0.3698 Test Loss: 0.6437 -  Test Accuracy: 0.3638\n",
      "Epoch: 2/5 - 21/03/2021 00:39:47 -  Training Loss: 0.6573 -  Training Accuracy: 0.3834 Test Loss: 0.5966 -  Test Accuracy: 0.4364\n",
      "Epoch: 3/5 - 21/03/2021 00:39:53 -  Training Loss: 0.6383 -  Training Accuracy: 0.4481 Test Loss: 0.5407 -  Test Accuracy: 0.6034\n",
      "Epoch: 4/5 - 21/03/2021 00:39:59 -  Training Loss: 0.6184 -  Training Accuracy: 0.5396 Test Loss: 0.5024 -  Test Accuracy: 0.6343\n",
      "Epoch: 5/5 - 21/03/2021 00:40:05 -  Training Loss: 0.6095 -  Training Accuracy: 0.5700 Test Loss: 0.5018 -  Test Accuracy: 0.8110\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:40:11 -  Training Loss: 0.6742 -  Training Accuracy: 0.3539 Test Loss: 0.6475 -  Test Accuracy: 0.3631\n",
      "Epoch: 2/10 - 21/03/2021 00:40:17 -  Training Loss: 0.6629 -  Training Accuracy: 0.3813 Test Loss: 0.5964 -  Test Accuracy: 0.3769\n",
      "Epoch: 3/10 - 21/03/2021 00:40:23 -  Training Loss: 0.6336 -  Training Accuracy: 0.4845 Test Loss: 0.5393 -  Test Accuracy: 0.6845\n",
      "Epoch: 4/10 - 21/03/2021 00:40:29 -  Training Loss: 0.6287 -  Training Accuracy: 0.5358 Test Loss: 0.5107 -  Test Accuracy: 0.5911\n",
      "Epoch: 5/10 - 21/03/2021 00:40:35 -  Training Loss: 0.6166 -  Training Accuracy: 0.5682 Test Loss: 0.5063 -  Test Accuracy: 0.8051\n",
      "Epoch: 6/10 - 21/03/2021 00:40:41 -  Training Loss: 0.6018 -  Training Accuracy: 0.5656 Test Loss: 0.4937 -  Test Accuracy: 0.7347\n",
      "Epoch: 7/10 - 21/03/2021 00:40:47 -  Training Loss: 0.5957 -  Training Accuracy: 0.5608 Test Loss: 0.4898 -  Test Accuracy: 0.7273\n",
      "Epoch: 8/10 - 21/03/2021 00:40:53 -  Training Loss: 0.5993 -  Training Accuracy: 0.5654 Test Loss: 0.4856 -  Test Accuracy: 0.7768\n",
      "Epoch: 9/10 - 21/03/2021 00:40:59 -  Training Loss: 0.5997 -  Training Accuracy: 0.5987 Test Loss: 0.4821 -  Test Accuracy: 0.7530\n",
      "Epoch: 10/10 - 21/03/2021 00:41:06 -  Training Loss: 0.5937 -  Training Accuracy: 0.5898 Test Loss: 0.4764 -  Test Accuracy: 0.7370\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:41:12 -  Training Loss: 0.6772 -  Training Accuracy: 0.3497 Test Loss: 0.6660 -  Test Accuracy: 0.3642\n",
      "Epoch: 2/5 - 21/03/2021 00:41:18 -  Training Loss: 0.6746 -  Training Accuracy: 0.3495 Test Loss: 0.6629 -  Test Accuracy: 0.3635\n",
      "Epoch: 3/5 - 21/03/2021 00:41:24 -  Training Loss: 0.6736 -  Training Accuracy: 0.3470 Test Loss: 0.6607 -  Test Accuracy: 0.3638\n",
      "Epoch: 4/5 - 21/03/2021 00:41:30 -  Training Loss: 0.6722 -  Training Accuracy: 0.3495 Test Loss: 0.6604 -  Test Accuracy: 0.3616\n",
      "Epoch: 5/5 - 21/03/2021 00:41:37 -  Training Loss: 0.6729 -  Training Accuracy: 0.3445 Test Loss: 0.6588 -  Test Accuracy: 0.3620\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:41:43 -  Training Loss: 0.6772 -  Training Accuracy: 0.3475 Test Loss: 0.6661 -  Test Accuracy: 0.3627\n",
      "Epoch: 2/10 - 21/03/2021 00:41:49 -  Training Loss: 0.6762 -  Training Accuracy: 0.3470 Test Loss: 0.6658 -  Test Accuracy: 0.3627\n",
      "Epoch: 3/10 - 21/03/2021 00:41:56 -  Training Loss: 0.6745 -  Training Accuracy: 0.3470 Test Loss: 0.6655 -  Test Accuracy: 0.3620\n",
      "Epoch: 4/10 - 21/03/2021 00:42:02 -  Training Loss: 0.6716 -  Training Accuracy: 0.3470 Test Loss: 0.6604 -  Test Accuracy: 0.3631\n",
      "Epoch: 5/10 - 21/03/2021 00:42:08 -  Training Loss: 0.6729 -  Training Accuracy: 0.3445 Test Loss: 0.6606 -  Test Accuracy: 0.3616\n",
      "Epoch: 6/10 - 21/03/2021 00:42:15 -  Training Loss: 0.6697 -  Training Accuracy: 0.3495 Test Loss: 0.6581 -  Test Accuracy: 0.3620\n",
      "Epoch: 7/10 - 21/03/2021 00:42:21 -  Training Loss: 0.6719 -  Training Accuracy: 0.3445 Test Loss: 0.6571 -  Test Accuracy: 0.3631\n",
      "Epoch: 8/10 - 21/03/2021 00:42:27 -  Training Loss: 0.6703 -  Training Accuracy: 0.3470 Test Loss: 0.6576 -  Test Accuracy: 0.3638\n",
      "Epoch: 9/10 - 21/03/2021 00:42:34 -  Training Loss: 0.6723 -  Training Accuracy: 0.3445 Test Loss: 0.6561 -  Test Accuracy: 0.3624\n",
      "Epoch: 10/10 - 21/03/2021 00:42:40 -  Training Loss: 0.6709 -  Training Accuracy: 0.3445 Test Loss: 0.6567 -  Test Accuracy: 0.3646\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:42:46 -  Training Loss: 0.6821 -  Training Accuracy: 0.3530 Test Loss: 0.6635 -  Test Accuracy: 0.3627\n",
      "Epoch: 2/5 - 21/03/2021 00:42:53 -  Training Loss: 0.6707 -  Training Accuracy: 0.3695 Test Loss: 0.6302 -  Test Accuracy: 0.3638\n",
      "Epoch: 3/5 - 21/03/2021 00:42:59 -  Training Loss: 0.6633 -  Training Accuracy: 0.4101 Test Loss: 0.5988 -  Test Accuracy: 0.5004\n",
      "Epoch: 4/5 - 21/03/2021 00:43:06 -  Training Loss: 0.6371 -  Training Accuracy: 0.4883 Test Loss: 0.5435 -  Test Accuracy: 0.7522\n",
      "Epoch: 5/5 - 21/03/2021 00:43:12 -  Training Loss: 0.6305 -  Training Accuracy: 0.5218 Test Loss: 0.5117 -  Test Accuracy: 0.6079\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:43:19 -  Training Loss: 0.6780 -  Training Accuracy: 0.3478 Test Loss: 0.6654 -  Test Accuracy: 0.3638\n",
      "Epoch: 2/10 - 21/03/2021 00:43:25 -  Training Loss: 0.6786 -  Training Accuracy: 0.3504 Test Loss: 0.6514 -  Test Accuracy: 0.3627\n",
      "Epoch: 3/10 - 21/03/2021 00:43:31 -  Training Loss: 0.6668 -  Training Accuracy: 0.3619 Test Loss: 0.6320 -  Test Accuracy: 0.3642\n",
      "Epoch: 4/10 - 21/03/2021 00:43:38 -  Training Loss: 0.6486 -  Training Accuracy: 0.4109 Test Loss: 0.5745 -  Test Accuracy: 0.4847\n",
      "Epoch: 5/10 - 21/03/2021 00:43:44 -  Training Loss: 0.6318 -  Training Accuracy: 0.4909 Test Loss: 0.5250 -  Test Accuracy: 0.6429\n",
      "Epoch: 6/10 - 21/03/2021 00:43:52 -  Training Loss: 0.6153 -  Training Accuracy: 0.5173 Test Loss: 0.5303 -  Test Accuracy: 0.6469\n",
      "Epoch: 7/10 - 21/03/2021 00:43:59 -  Training Loss: 0.6127 -  Training Accuracy: 0.5144 Test Loss: 0.5244 -  Test Accuracy: 0.6477\n",
      "Epoch: 8/10 - 21/03/2021 00:44:06 -  Training Loss: 0.6105 -  Training Accuracy: 0.5211 Test Loss: 0.5265 -  Test Accuracy: 0.6477\n",
      "Epoch: 9/10 - 21/03/2021 00:44:13 -  Training Loss: 0.6124 -  Training Accuracy: 0.5125 Test Loss: 0.5276 -  Test Accuracy: 0.6477\n",
      "Epoch: 10/10 - 21/03/2021 00:44:21 -  Training Loss: 0.6132 -  Training Accuracy: 0.5179 Test Loss: 0.5253 -  Test Accuracy: 0.6496\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:44:28 -  Training Loss: 0.6759 -  Training Accuracy: 0.3475 Test Loss: 0.6641 -  Test Accuracy: 0.3631\n",
      "Epoch: 2/5 - 21/03/2021 00:44:35 -  Training Loss: 0.6741 -  Training Accuracy: 0.3495 Test Loss: 0.6639 -  Test Accuracy: 0.3638\n",
      "Epoch: 3/5 - 21/03/2021 00:44:42 -  Training Loss: 0.6710 -  Training Accuracy: 0.3470 Test Loss: 0.6586 -  Test Accuracy: 0.3635\n",
      "Epoch: 4/5 - 21/03/2021 00:44:48 -  Training Loss: 0.6698 -  Training Accuracy: 0.3470 Test Loss: 0.6572 -  Test Accuracy: 0.3627\n",
      "Epoch: 5/5 - 21/03/2021 00:44:55 -  Training Loss: 0.6643 -  Training Accuracy: 0.3495 Test Loss: 0.6482 -  Test Accuracy: 0.3638\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:45:03 -  Training Loss: 0.6790 -  Training Accuracy: 0.3448 Test Loss: 0.6695 -  Test Accuracy: 0.3635\n",
      "Epoch: 2/10 - 21/03/2021 00:45:10 -  Training Loss: 0.6734 -  Training Accuracy: 0.3495 Test Loss: 0.6647 -  Test Accuracy: 0.3627\n",
      "Epoch: 3/10 - 21/03/2021 00:45:17 -  Training Loss: 0.6753 -  Training Accuracy: 0.3470 Test Loss: 0.6632 -  Test Accuracy: 0.3631\n",
      "Epoch: 4/10 - 21/03/2021 00:45:24 -  Training Loss: 0.6738 -  Training Accuracy: 0.3445 Test Loss: 0.6631 -  Test Accuracy: 0.3616\n",
      "Epoch: 5/10 - 21/03/2021 00:45:31 -  Training Loss: 0.6704 -  Training Accuracy: 0.3495 Test Loss: 0.6575 -  Test Accuracy: 0.3631\n",
      "Epoch: 6/10 - 21/03/2021 00:45:38 -  Training Loss: 0.6711 -  Training Accuracy: 0.3445 Test Loss: 0.6579 -  Test Accuracy: 0.3627\n",
      "Epoch: 7/10 - 21/03/2021 00:45:45 -  Training Loss: 0.6694 -  Training Accuracy: 0.3470 Test Loss: 0.6592 -  Test Accuracy: 0.3646\n",
      "Epoch: 8/10 - 21/03/2021 00:45:52 -  Training Loss: 0.6696 -  Training Accuracy: 0.3495 Test Loss: 0.6566 -  Test Accuracy: 0.3631\n",
      "Epoch: 9/10 - 21/03/2021 00:45:59 -  Training Loss: 0.6704 -  Training Accuracy: 0.3495 Test Loss: 0.6576 -  Test Accuracy: 0.3624\n",
      "Epoch: 10/10 - 21/03/2021 00:46:06 -  Training Loss: 0.6698 -  Training Accuracy: 0.3470 Test Loss: 0.6573 -  Test Accuracy: 0.3638\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:46:14 -  Training Loss: 0.6798 -  Training Accuracy: 0.3621 Test Loss: 0.6611 -  Test Accuracy: 0.3627\n",
      "Epoch: 2/5 - 21/03/2021 00:46:21 -  Training Loss: 0.6676 -  Training Accuracy: 0.3673 Test Loss: 0.6298 -  Test Accuracy: 0.3627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/5 - 21/03/2021 00:46:28 -  Training Loss: 0.6508 -  Training Accuracy: 0.4035 Test Loss: 0.5964 -  Test Accuracy: 0.7679\n",
      "Epoch: 4/5 - 21/03/2021 00:46:35 -  Training Loss: 0.6364 -  Training Accuracy: 0.4987 Test Loss: 0.5168 -  Test Accuracy: 0.6276\n",
      "Epoch: 5/5 - 21/03/2021 00:46:42 -  Training Loss: 0.6269 -  Training Accuracy: 0.5396 Test Loss: 0.5056 -  Test Accuracy: 0.6949\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:46:49 -  Training Loss: 0.6746 -  Training Accuracy: 0.3570 Test Loss: 0.6432 -  Test Accuracy: 0.3635\n",
      "Epoch: 2/10 - 21/03/2021 00:46:56 -  Training Loss: 0.6528 -  Training Accuracy: 0.4219 Test Loss: 0.5827 -  Test Accuracy: 0.5848\n",
      "Epoch: 3/10 - 21/03/2021 00:47:03 -  Training Loss: 0.6302 -  Training Accuracy: 0.4899 Test Loss: 0.5314 -  Test Accuracy: 0.7872\n",
      "Epoch: 4/10 - 21/03/2021 00:47:10 -  Training Loss: 0.6105 -  Training Accuracy: 0.5616 Test Loss: 0.4853 -  Test Accuracy: 0.7928\n",
      "Epoch: 5/10 - 21/03/2021 00:47:16 -  Training Loss: 0.6014 -  Training Accuracy: 0.5982 Test Loss: 0.4558 -  Test Accuracy: 0.7243\n",
      "Epoch: 6/10 - 21/03/2021 00:47:23 -  Training Loss: 0.5848 -  Training Accuracy: 0.6041 Test Loss: 0.4575 -  Test Accuracy: 0.7928\n",
      "Epoch: 7/10 - 21/03/2021 00:47:31 -  Training Loss: 0.5911 -  Training Accuracy: 0.6223 Test Loss: 0.4547 -  Test Accuracy: 0.7809\n",
      "Epoch: 8/10 - 21/03/2021 00:47:38 -  Training Loss: 0.5849 -  Training Accuracy: 0.6072 Test Loss: 0.4511 -  Test Accuracy: 0.7757\n",
      "Epoch: 9/10 - 21/03/2021 00:47:45 -  Training Loss: 0.5858 -  Training Accuracy: 0.6002 Test Loss: 0.4524 -  Test Accuracy: 0.7894\n",
      "Epoch: 10/10 - 21/03/2021 00:47:52 -  Training Loss: 0.5852 -  Training Accuracy: 0.6246 Test Loss: 0.4463 -  Test Accuracy: 0.8073\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:47:59 -  Training Loss: 0.6790 -  Training Accuracy: 0.3626 Test Loss: 0.6673 -  Test Accuracy: 0.3631\n",
      "Epoch: 2/5 - 21/03/2021 00:48:06 -  Training Loss: 0.6733 -  Training Accuracy: 0.3495 Test Loss: 0.6663 -  Test Accuracy: 0.3616\n",
      "Epoch: 3/5 - 21/03/2021 00:48:13 -  Training Loss: 0.6766 -  Training Accuracy: 0.3445 Test Loss: 0.6645 -  Test Accuracy: 0.3616\n",
      "Epoch: 4/5 - 21/03/2021 00:48:20 -  Training Loss: 0.6752 -  Training Accuracy: 0.3470 Test Loss: 0.6647 -  Test Accuracy: 0.3631\n",
      "Epoch: 5/5 - 21/03/2021 00:48:27 -  Training Loss: 0.6736 -  Training Accuracy: 0.3470 Test Loss: 0.6615 -  Test Accuracy: 0.3620\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:48:34 -  Training Loss: 0.6756 -  Training Accuracy: 0.3495 Test Loss: 0.6691 -  Test Accuracy: 0.3635\n",
      "Epoch: 2/10 - 21/03/2021 00:48:41 -  Training Loss: 0.6769 -  Training Accuracy: 0.3445 Test Loss: 0.6682 -  Test Accuracy: 0.3627\n",
      "Epoch: 3/10 - 21/03/2021 00:48:48 -  Training Loss: 0.6746 -  Training Accuracy: 0.3470 Test Loss: 0.6677 -  Test Accuracy: 0.3616\n",
      "Epoch: 4/10 - 21/03/2021 00:48:55 -  Training Loss: 0.6739 -  Training Accuracy: 0.3470 Test Loss: 0.6642 -  Test Accuracy: 0.3631\n",
      "Epoch: 5/10 - 21/03/2021 00:49:01 -  Training Loss: 0.6755 -  Training Accuracy: 0.3445 Test Loss: 0.6644 -  Test Accuracy: 0.3635\n",
      "Epoch: 6/10 - 21/03/2021 00:49:08 -  Training Loss: 0.6724 -  Training Accuracy: 0.3470 Test Loss: 0.6633 -  Test Accuracy: 0.3631\n",
      "Epoch: 7/10 - 21/03/2021 00:49:16 -  Training Loss: 0.6723 -  Training Accuracy: 0.3445 Test Loss: 0.6615 -  Test Accuracy: 0.3635\n",
      "Epoch: 8/10 - 21/03/2021 00:49:22 -  Training Loss: 0.6706 -  Training Accuracy: 0.3470 Test Loss: 0.6627 -  Test Accuracy: 0.3620\n",
      "Epoch: 9/10 - 21/03/2021 00:49:29 -  Training Loss: 0.6727 -  Training Accuracy: 0.3470 Test Loss: 0.6654 -  Test Accuracy: 0.3620\n",
      "Epoch: 10/10 - 21/03/2021 00:49:36 -  Training Loss: 0.6733 -  Training Accuracy: 0.3470 Test Loss: 0.6607 -  Test Accuracy: 0.3642\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:49:43 -  Training Loss: 0.6771 -  Training Accuracy: 0.3455 Test Loss: 0.6660 -  Test Accuracy: 0.3653\n",
      "Epoch: 2/5 - 21/03/2021 00:49:50 -  Training Loss: 0.6601 -  Training Accuracy: 0.4062 Test Loss: 0.6001 -  Test Accuracy: 0.3832\n",
      "Epoch: 3/5 - 21/03/2021 00:49:57 -  Training Loss: 0.6275 -  Training Accuracy: 0.4974 Test Loss: 0.5141 -  Test Accuracy: 0.5446\n",
      "Epoch: 4/5 - 21/03/2021 00:50:04 -  Training Loss: 0.6148 -  Training Accuracy: 0.5619 Test Loss: 0.4735 -  Test Accuracy: 0.7612\n",
      "Epoch: 5/5 - 21/03/2021 00:50:11 -  Training Loss: 0.5987 -  Training Accuracy: 0.6096 Test Loss: 0.4746 -  Test Accuracy: 0.8021\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:50:18 -  Training Loss: 0.6759 -  Training Accuracy: 0.3471 Test Loss: 0.6766 -  Test Accuracy: 0.8125\n",
      "Epoch: 2/10 - 21/03/2021 00:50:25 -  Training Loss: 0.6585 -  Training Accuracy: 0.3905 Test Loss: 0.5950 -  Test Accuracy: 0.3650\n",
      "Epoch: 3/10 - 21/03/2021 00:50:32 -  Training Loss: 0.6324 -  Training Accuracy: 0.4819 Test Loss: 0.5463 -  Test Accuracy: 0.7935\n",
      "Epoch: 4/10 - 21/03/2021 00:50:39 -  Training Loss: 0.6142 -  Training Accuracy: 0.5692 Test Loss: 0.4944 -  Test Accuracy: 0.7117\n",
      "Epoch: 5/10 - 21/03/2021 00:50:46 -  Training Loss: 0.6053 -  Training Accuracy: 0.5879 Test Loss: 0.4853 -  Test Accuracy: 0.7965\n",
      "Epoch: 6/10 - 21/03/2021 00:50:52 -  Training Loss: 0.6005 -  Training Accuracy: 0.6703 Test Loss: 0.4820 -  Test Accuracy: 0.7946\n",
      "Epoch: 7/10 - 21/03/2021 00:50:59 -  Training Loss: 0.5961 -  Training Accuracy: 0.6716 Test Loss: 0.4810 -  Test Accuracy: 0.7920\n",
      "Epoch: 8/10 - 21/03/2021 00:51:06 -  Training Loss: 0.6028 -  Training Accuracy: 0.6554 Test Loss: 0.4810 -  Test Accuracy: 0.7790\n",
      "Epoch: 9/10 - 21/03/2021 00:51:13 -  Training Loss: 0.5996 -  Training Accuracy: 0.6663 Test Loss: 0.4828 -  Test Accuracy: 0.7779\n",
      "Epoch: 10/10 - 21/03/2021 00:51:20 -  Training Loss: 0.5948 -  Training Accuracy: 0.6609 Test Loss: 0.4825 -  Test Accuracy: 0.7738\n",
      "using GPU\n",
      "Epoch: 1/5 - 21/03/2021 00:51:28 -  Training Loss: 0.6762 -  Training Accuracy: 0.3559 Test Loss: 0.6653 -  Test Accuracy: 0.3646\n",
      "Epoch: 2/5 - 21/03/2021 00:51:35 -  Training Loss: 0.6770 -  Training Accuracy: 0.3445 Test Loss: 0.6662 -  Test Accuracy: 0.3631\n",
      "Epoch: 3/5 - 21/03/2021 00:51:42 -  Training Loss: 0.6739 -  Training Accuracy: 0.3495 Test Loss: 0.6633 -  Test Accuracy: 0.3638\n",
      "Epoch: 4/5 - 21/03/2021 00:51:49 -  Training Loss: 0.6734 -  Training Accuracy: 0.3470 Test Loss: 0.6627 -  Test Accuracy: 0.3624\n",
      "Epoch: 5/5 - 21/03/2021 00:51:56 -  Training Loss: 0.6706 -  Training Accuracy: 0.3470 Test Loss: 0.6610 -  Test Accuracy: 0.3646\n",
      "using GPU\n",
      "Epoch: 1/10 - 21/03/2021 00:52:03 -  Training Loss: 0.6755 -  Training Accuracy: 0.3492 Test Loss: 0.6667 -  Test Accuracy: 0.3624\n",
      "Epoch: 2/10 - 21/03/2021 00:52:10 -  Training Loss: 0.6757 -  Training Accuracy: 0.3445 Test Loss: 0.6612 -  Test Accuracy: 0.3638\n",
      "Epoch: 3/10 - 21/03/2021 00:52:17 -  Training Loss: 0.6749 -  Training Accuracy: 0.3445 Test Loss: 0.6583 -  Test Accuracy: 0.3631\n",
      "Epoch: 4/10 - 21/03/2021 00:52:24 -  Training Loss: 0.6718 -  Training Accuracy: 0.3495 Test Loss: 0.6563 -  Test Accuracy: 0.3627\n",
      "Epoch: 5/10 - 21/03/2021 00:52:31 -  Training Loss: 0.6727 -  Training Accuracy: 0.3445 Test Loss: 0.6539 -  Test Accuracy: 0.3627\n",
      "Epoch: 6/10 - 21/03/2021 00:52:38 -  Training Loss: 0.6692 -  Training Accuracy: 0.3495 Test Loss: 0.6558 -  Test Accuracy: 0.3616\n",
      "Epoch: 7/10 - 21/03/2021 00:52:45 -  Training Loss: 0.6698 -  Training Accuracy: 0.3495 Test Loss: 0.6572 -  Test Accuracy: 0.3631\n",
      "Epoch: 8/10 - 21/03/2021 00:52:52 -  Training Loss: 0.6716 -  Training Accuracy: 0.3445 Test Loss: 0.6568 -  Test Accuracy: 0.3616\n",
      "Epoch: 9/10 - 21/03/2021 00:52:59 -  Training Loss: 0.6723 -  Training Accuracy: 0.3470 Test Loss: 0.6538 -  Test Accuracy: 0.3624\n",
      "Epoch: 10/10 - 21/03/2021 00:53:06 -  Training Loss: 0.6686 -  Training Accuracy: 0.3495 Test Loss: 0.6547 -  Test Accuracy: 0.3627\n"
     ]
    }
   ],
   "source": [
    "# epochs\n",
    "train_model_L1(epochs= 5, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "\n",
    "# learning rate\n",
    "train_model_L1(epochs= 5, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 10, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.5)\n",
    "\n",
    "# scheduler gamma\n",
    "train_model_L1(epochs= 5, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 5, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "train_model_L1(epochs= 10, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.5)\n",
    "\n",
    "# l1 lambda\n",
    "train_model_L1(epochs= 5, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 5, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 10, lr=0.00001, scheduler_gamma=0.1, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 5, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 10, lr=0.0001, scheduler_gamma=0.001, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 5, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.01)\n",
    "train_model_L1(epochs= 10, lr=0.00001, scheduler_gamma=0.001, l1_lambda=0.01)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "custom_dataset_dataloader_cascade.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
